{"meta":{"title":"Charles","subtitle":null,"description":null,"author":"Charles","url":"http://Charles-xcz.github.io","root":"/"},"posts":[{"tags":[{"name":"多线程","slug":"多线程","permalink":"http://Charles-xcz.github.io/tags/多线程/"},{"name":"CAS","slug":"CAS","permalink":"http://Charles-xcz.github.io/tags/CAS/"}],"title":"并发编程之—— CAS","date":"2020/03/11","text":"引言 CAS：Compare-And-Swap 比较并交换，它是一条CPU并发原语 它的功能是判断内存某个位置的值是否为预期值，如果是则更改为新的值，这个过程是原子的。 1. CAS的底层原理原子整型的原子自增就是通过CAS的原理实现的。 AtomicInteger atomicInteger=new AtomicInteger(5); atomicInteger.getAndIncrement; 下面通过AtomicInteger类的源码例子来了解CAS是什么： public class AtomicInteger extends Number implements java.io.Serializable &#123; private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(\"value\")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile int value; ....... /** * Atomically increments by one the current value. * * @return the previous value */ public final int getAndIncrement() &#123; return unsafe.getAndAddInt(this, valueOffset, 1); &#125; 可以看到AtomicInteger类中引入了一个Unsafe类，CAS是通过Unsafe类实现的。 先了解一下Unsafe类 Unsafe是CAS的核心类，由于Java方法无法直接访问底层系统，需要通过本地（native）方法来访问，Unsafe相当于一个后门，基于该类可以直接操作特定内存的数据。Unsafe类存在于sun.misc包中，其内部方法操作可以像C的指针一样直接操作内存，因为Java中CAS操作的执行依赖于Unsafe类的方法。 ​ 注意：Unsafe类中的所有方法都是native修饰的，也就是Unsafe类中的方法都直接调用操作系统层资源执行相应任务。 变量valueOffset，表示该变量值在内存中的偏移地址，因为Unsafe类就是根据内存偏移地址获取数据的。 3. 变量value用volatile修饰，保证了多线程之间的内存可见性。 //Unsafe类中的getAndAddInt方法 public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; &#125; ​ CAS并发原语在JAVA语言中就是sun.misc.Unsafe类中的各个方法实现的。 ​ 调用UnSafe类中的CAS方法，JVM会帮我们实现出CAS汇编指令。这是一种完全依赖于硬件的功能，通过它实现了原子操作。 ​ 再次强调，由于CAS是一种系统原语，原语属于操作系统用语范畴，是由若干条指令组成的，用于完成某个功能的一个过程，并且原语的执行必须是连续的，在执行过程中不允许被中断，也就是说CAS是一条CPU的原子指令，不会造成所谓的数据不一致问题。 ​ 假设线程A和线程B两个线程同时执行getAndAddlnt操作实现过程（分别跑在不同CPU上）： Atomiclnteger里面的value原始值为3，即主内存中Atomiclnteger的value为3，根据JMM模型，线程A和线程B各自持有一份值为3的value的副本分别到各自的工作内存。 线程A通过getIntVolatile(var1,var2)拿到value值3，这时线程A被挂起。 线程B也通过getIntVolatile(var1,var2)方法获取到value值3，此时刚好线程B没有被挂起并执行compareAndSwaplnt方法比较内存值也为3，成功修改内存值为4，线程B完成收工，一切OK。 这时线程A恢复，执行compareAndSwaplnt方法比较，发现自己手里的值数字3和主内存的值数字4不一致，说明该值己经被其它线程抢先一步修改过了，那A线程本次修改失败，只能重新读取重新来一遍了。 线程A重新获取value值，因为变量value被volatile修饰，所以其它线程对它的修改，线程A总是能够看到，线程A继续执行compareAndSwaplnt进行比较替换，直到成功。 即：比较当前工作内存的值和主内存中的值，如果相同则执行规定操作，否则继续比较直到主内存和工作内存中的值一致为止。 2. CAS缺点 由于通过do while循环实现，可能导致循环时间长，cpu开销大。 只能保证一个共享变量的原子操作。 当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就要使用锁来保证原子性。 引出来ABA问题 3. ABA问题​ CAS算法实现一个重要前提需要取出内存中某时刻的数据并在当下时刻比较并替换，那么在这个时间差类会导致数据的变化。 ​ 比如说一个线程1从内存位置V中取出A，这时候另一个线程2也从内存中取出A，并且线程2进行了一些操作将值变成了B，然后线程2又将V位置的数据变成A，这时候线程1进行CAS操作发现内存中仍然是A，然后线程1操作成功。 ​ 尽管这个过程线程1的CAS操作成功，但内存V位置的值中间产生了变化，有时这种问题会造成影响，这就叫做ABA问题。 解决ABA问题 ​ 新增一种机制，版本号（类似于时间戳） 原子引用：AtomicInteger，只是对基本类型进行原子操作，要想对对象进行原子操作，可使用原子引用类型。 AtomicReference&lt;T&gt; //不带版本号 AtomicReference&lt;Integer&gt; 等同于 AtomicInteger AtomicStampedReference&lt;T&gt; //带版本号的原子引用，可以解决ABA问题","permalink":"http://Charles-xcz.github.io/2020/03/11/CAS/","photos":[]},{"tags":[{"name":"JVM","slug":"JVM","permalink":"http://Charles-xcz.github.io/tags/JVM/"}],"title":"JVM学习(2)——JVM的堆/栈/方法区以及GC算法","date":"2020/03/01","text":"一. 方法区 Method Area属于供各线程共享的运行时内存区域。 它存储了每一个类的结构信息，例如运行时常量池（Runtime Constant Poo1）、字段和方法数据、构造函数和普通方法的字节码内容。 方法区所说的是一种规范，在不同虚拟机里头实现是不一样的，最典型的就是： 永久代（PermGen Space） JDK7 中的实现 元空间（Meta Space） JDK8 中的实现 实例变量存在堆内存中，和方法区无关。 二. Stack栈也叫栈内存，主管Java程序的运行，是在线程创建时创建，它的生命期是跟随线程的生命期，线程结束栈内存也就释放，对于栈来说不存在垃圾回收问题，只要线程一结束该栈就0ver，生命周期和线程一致，是线程私有的。 8种基本类型的变量+对象的引用变量+实例方法都是在函数的栈内存中分配。 栈帧中主要保存3类数据：（每个方法入栈就是一个栈帧） 本地变量（Local Variables）：输入参数和输出参数以及方法内的变量； 栈操作（Operand Stack）：记录出栈、入栈的操作； 栈帧数据（Frame Data）：包括类文件、方法等等。 栈运行原理： 栈中的数据都是以栈帧（Stack Frame）的格式存在，栈帧是一个内存区块，是一个数据集，是一个有关方法（Method）和运行期数据的数据集，当一个方法A被调用时就产生了一个栈帧F1，并被压入到栈中，A方法又调用了B方法，于是产生栈帧F2也被压入栈，B方法又调用了C方法，于是产生栈帧F3也被压入栈，执行完毕后，先弹出F3栈帧，再弹出F2栈帧，再弹出F1栈帧…… 遵循“先进后出”/“后进先出”原则。 每个方法执行的同时都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接、方法出口等信息，每一个方法从调用直至执行完毕的过程，就对应着一个栈帧在虚拟机中入栈到出栈的过程。栈的大小和具体JVM的实现有关，通常在256K~756K之间，与等于1Mb左右。 //Exception in thread \"main\" java.lang.StackOverflowError 栈溢出错误 public Class Test&#123; public static void m1()&#123; m1(); &#125; public static void main(String[]args)&#123; m1(); &#125; &#125; Java堆+栈+方法区的交互关系 HotSpot是使用指针的方式来访问对象。 Java堆中会存放r访问类元数据的地址，reference存储的就是直接对象的地址。 三. 堆Heap堆的划分 逻辑上 新生代 (Young/New Generation Space) 伊甸园区(Eden Space) 幸存者0区(Survivor 0 Space) 幸存者1区(Survivor 1 Space) 老年代(Tenure/Old Generation Space) 永久代(Permanent Space)(Java7之前)/元空间(Meta Space)(Java8) 物理上 新生代 老年代 1. 新生代​ 新生区是类的诞生、成长、消亡的区域，一个类在这里产生，应用，最后被垃圾回收器收集，结束生命。 ​ 新生区又分为两部分：伊甸区（Eden space）和幸存者区（Survivor pace），所有的类都是在伊甸区被new出来的。 ​ 幸存者区有两个：0区（Survivor 0 space）和1区（Survivor 1 space）。 ​ 当伊甸园的空间用完时，程序又需要创建对象，JVM的垃圾回收器将对伊甸园区进行垃圾回收（Minor GC），将伊甸园区中的不再被其他对象所引用的对象进行销毁。然后将伊甸园中的剩余对象移动到幸存0区。若幸存0区也满了，再对该区进行垃圾回收，然后移动到1区。那如果1区也满了呢？再移动到养老区。 ​ 若养老区也满了，那么这个时候将产生MajorGC(Full GC)，进行养老区的内存清理。若养老区执行了Fu11 GC之后发现依然无法进行对象的保存，就会产生OOM异常“OutOfMemoryError”。 如果出现java.lang.OutOfMemoryError:Java heap space异常，说明Java虚拟机的堆内存不够。原因有二：（1）Java虚拟机的堆内存设置不够，可以通过参数-Xms、-Xmx来调整。（2）代码中创建了大量大对象，并且长时间不能被垃圾收集器收集（存在被引用）。 2. Minor GC的过程（复制-&gt;清空-&gt;互换） 首先，当Eden区满的时候会触发第一次GC，把还活着的对象拷贝到SurvivorFrom区。经历一次复制，年龄+1。 在触发GC的时候，对象只会存在于Eden区和名为“From”的Survivor区，Survivor区“To”是必定是空的。 紧接着进行GC，Eden区中所有存活的对象都会被复制到“To”，而在“From”区中，仍存活的对象会根据他们的年龄值来决定去向。年龄达到一定值（年龄阈值，默认为15。可以通过-XX:MaxTenuringThreshold来设置）的对象会被移动到年老代中，没有达到阈值的对象会被复制到“To”区域。 经过这次GC后，Eden区和From区已经被清空。这个时候，“From”和“To”会交换他们的角色，也就是新的“To”就是上次GC前的“From”，新的“From”就是上次GC前的“To”。不管怎样，都会保证名为To的Survivor区域是空的。 Minor GC会一直重复这样的过程，直到“To”区被填满，“To”区被填满之后，会将所有对象移动到年老代中。 3. 永久代​ 实际而言，方法区（Method Area）和堆一样，是各个线程共享的内存区域。 ​ 它用于存储虚拟机加载的：类信息+普通常量+静态常量+编译器编译后的代码等等。 ​ 虽然JVM规范将方法区描述为堆的一个逻辑部分，但它却还有一个别名叫做Non-Heap（非堆），目的就是要和堆分开。 ​ 对于HotSpot虚拟机，很多开发者习惯将方法区称之为“永久代（Parmanent Gen）”，但严格本质上说两者不同，或者说使用永久代来实现方法区而已，永久代是方法区的一个实现，Jdk1.7的版本中，已经将原本放在永久代的字符串常量池移走。 ​ 永久存储区是一个常驻内存区域，用于存放JDK自身所携带的Class，Interface的元数据，也就是说它存储的是运行环境必须的类信息，被装载进此区域的数据是不会被垃圾回收器回收掉的，关闭JVM才会释放此区域所占用的内存。 4. 堆参数调整 在Java8中，永久代已经被移除，被一个称为元空间的区域所取代。元空间的本质和永久代类似。 元空间与永久代之间最大的区别在于： 永久代使用的JVM的堆内存，但是java8以后的元空间并不在虚拟机中而是使用本机物理内存。 因此，默认情况下，元空间的大小仅受本地内存限制。类的元数据放入native memory，字符串池和类的静态变量放入java堆中，这样可以加载多少类的元数据就不再由MaxPermSize控制，而由系统的实际可用空间来控制。 JVM默认情况下分配的初始堆内存为机器物理内存的1/64，最大为1/4 可以通过代码查看： /** * 查看虚拟机内存情况 * @author charles * @date 2020/3/1 16:51 */ public class MyTest1 &#123; public static void main(String[] args) &#123; System.out.println(\"cpu核数:\"+Runtime.getRuntime().availableProcessors()); System.out.println(\"初始分配内存Xms: \"+Runtime.getRuntime().totalMemory()/(double)1024/1024+\" MB\"); System.out.println(\"最大分配内存Xmx: \"+Runtime.getRuntime().maxMemory()/(double)1024/1024+\" MB\"); &#125; &#125; 修改VM参数后： VM options: -Xms1024m -Xmx1024m -XX:+PrintGCDetails 写个程序造成OOM异常，观察下GC日志 OOM异常：Exception in thread “main” java.lang.OutOfMemoryError: Java heap space 先将将分配空间调小 -Xms10m -Xmx10m -XX:+PrintGCDetails public class MyTest1 &#123; public static void main(String[] args) &#123; //new 一个超出限制的对象，或者写个循环 new大量的对象 byte[] bytes = new byte[20 * 1024 * 10244]; &#125; &#125; GC日志： [GC (Allocation Failure) [PSYoungGen: 1564K-&gt;488K(2560K)] 1564K-&gt;684K(9728K), 0.0007243 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (Allocation Failure) [PSYoungGen: 504K-&gt;0K(2560K)] [ParOldGen: 268K-&gt;593K(7168K)] 772K-&gt;593K(9728K), [Metaspace: 3173K-&gt;3173K(1056768K)], 0.0054369 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] GC日志解读： Full GC结构类似。 五. GC算法 GC: Garbage Collection 1. GC算法概述GC 分代收集算法 次数上频繁收集Young区 次数上较少收集Old区 基本不动元空间 ​ JVM在进行GC时，并非每次都对上面三个内存区域一起回收的，大部分时候回收的都是指新生代。 ​ 因此GC按照回收的区域又分了两种类型，一种是普通GC（minorGC），一种是全局GC（major GC or Full GC） Minor GC和Full GC的区别 ​ 普通GC（minorGC）：只针对新生代区域的GC，指发生在新生代的垃圾收集动作，因为大多数Java对象存活率都不高，所以Minor GC非常频繁，一般回收速度也比较快。 ​ 全局GC（major GCor Full GC）：指发生在老年代的垃圾收集动作。出现了Major GC，经常会伴随至少一次的Minor GC（但并不是绝对的）。Major GC的速度一般要比Minor GC慢上10倍以上 2. 四大算法1. 引用计数法 注意：JVM的实现基本不采用该算法。 应用：（微软的COM/ActionScrip3/Python.… ） 给对象添加一个引用计数器，每当一个地方引用它时，计数器加1，每当引用失效时，计数器减少1。当计数器的数值为0时，也就是对象无法被引用时，表明对象不可再使用，这种方法实现简单，效率较高，大部分情况下不失为一个有效的方法。但是主流的Java虚拟机如HotSpot并没有选取引用计数法来回收内存，主要的原因难以解决对象之间的相互循环引用的问题。优点：实现简单，效率较高。 缺点： 每次对象赋值时均要维护引用计数器，且计数器本身也有一定的消耗。 较难处理循环引用。 2. 复制算法（Copying） 年轻代中使用的Minor GC，就是采用的复制算法。 ​ 因为年轻代的对象基本都是朝生夕死的（90%以上），所以在年轻代的垃圾回收算法使用的是复制算法。 ​ 复制算法的基本思想就是将内存分为两块，每次只用其中一块，当这一块内存用完，就将还活着的对象复制到另外一块上面。复制算法不会产生内存碎片。 优点： 没有标记和清除的过程，效率高。 没有内存碎片，可快速分配内存 缺点： 浪费空间：要从From区复制到To区，等于浪费一半的空间。 如果对象的存活率很高，我们可以极端一点，假设是100%存活，那么我们需要将所有对象都复制一遍，并将所有引用地址重置一遍。复制这一工作所花费的时间，在对象存活率达到一定程度时，将会变的不可忽视。所以从以上描述不难看出，复制算法要想使用，最起码对象的存活率要非常低才行，而且最重要的是，我们必须要克服50%内存的浪费。 ​ 因为Eden区对象一般存活率较低：一般的，使用两块10%的内存作为空闲和活动区间，而另外80%的内存，则是用来给新建对象分配内存的。一旦发生GC，将10%的from活动区间与另外80%中存活的eden对象转移到10%的to空闲区间，接下来，将之前90%的内存全部释放，以此类推。 ​ 具体的Minor GC的过程，前面已经论述过了，不再赘述。 3. 标记清除（Mark-Sweep） 老年代一般是由标记清除或者是标记清除与标记整理的混合实现。 算法分成标记和清除两个阶段，先标记出要回收的对象，然后统一回收这些对象。例如 ​ 先标记处要回收的对象(蓝色)，然后清除这些对象。 优点：不需要额外空间。 缺点： 耗时严重：两次扫描，效率比较低（递归与全堆对象遍历），而且在进行GC的时候，需要停止应用程序，这会导致用户体验非常差劲 产生内存碎片：这种方式清理出来的空闲内存是不连续的，这点不难理解，我们的死亡对象都是随即的出现在内存的各个角落的，现在把它们清除之后，内存的布局自然会乱七八糟。而为了应付这一点，JVM就不得不维持一个内存的空闲列表，这又是一种开销。而且在分配数组对象的时候，寻找连续的内存空间会不太好找。 4. 标记压缩（Mark-Compact） 实际上就是标记清除和标记整理(压缩)的结合。 ​ 先标记，然后再次扫描，将存活对象向一端移动。在整理压缩阶段，不对标记的对象进行回收，而是将所有存活对象移动到一端后，直接清除边界以外的内存。 优点： 不需要额外空间 没有内存碎片 缺点：需要移动对象，效率低 标记-清除-压缩 ​ 属于一种优化，就是多次GC（采用Mark-Sweep），后进行一次Compact。 5. 总结 效率方面：复制算法&gt;标记清除算法&gt;标记整理算法（此处的效率只是简单的对比时间复杂度，实际情况不一定如此）。 内存整齐度：复制算法=标记整理算法&gt;标记清除算法。 内存利用率：标记整理算法=标记清除算法&gt;复制算法。 ​ 可以看出，效率上来说，复制算法最优，但是却浪费了太多内存，而为了尽量兼顾上面所提到的三个指标，标记/整理算法相对来说更平滑一些，但效率上依然不尽如人意，它比复制算法多了一个标记的阶段，又比标记/清除多了一个整理内存的过程。 有没有更好的算法？有！本文的GC算法针对的是Java8中涉及的GC算法。 Java9以后默认采用的G1算法，以后再做介绍。","permalink":"http://Charles-xcz.github.io/2020/03/01/JVM内存分析/","photos":[]},{"tags":[{"name":"JVM","slug":"JVM","permalink":"http://Charles-xcz.github.io/tags/JVM/"}],"title":"JVM学习(1)——类加载、连接与初始化","date":"2020/02/29","text":"在Java代码中，类型的加载、连接与初始化过程都是在程序运行期间完成的。这提供了更大的灵活性，增加了更多的可能性 1. Java虚拟机与程序的生命周期 如下几种情况下，Java虚拟机将结束生命周期 执行了System.exit()方法 程序正常执行结束 程序在执行过程中遇到了异常或错误而异常终止 由于操作系统出现错误而导致Java虚拟机进程终止 2. 加载​ 查找并加载类的二进制数据，就是将二进制形式的Java类型读入Java虚拟机中。 ​ 类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内。然后在内存中创建一个java.lang.Class对象（规范并未说明Class对象位于哪里，HotSpot虚拟机将其放在了方法区中）用来封装类在方法区内的数据结构。 加载.class文件的方式 从本地系统中直接加载 通过网络下载.class文件 从zip，jar等归档文件中加载.class文件 从专有数据库中提取.class文件 将Java源文件动态编译为.class文件 3. 连接​ 类被加载后，就进入连接阶段。分为验证，准备，解析三个阶段 ​ 连接就是将已经读到内存中的类的二进制数据合并到虚拟机的运行环境中去。 ​ 验证：确保被加载类的正确性 ​ 类验证的内容 类文件的结构检查 语义检查 字节码验证 二进制兼容性的验证 ​ 准备：Java虚拟机为类的静态变量分配内存，并将其初始化为默认值 ​ 解析：把类中的符号引用（间接）转换为直接引用 4. 初始化​ 为类的静态变量赋予正确的初始值 ​ 静态变量的声明语句，以及静态代码块都被看做类的初始化语句。 ​ Java虚拟机会按照初始化语句在类文件中的先后顺序依次执行它们。 ​ 类初始化步骤 假如这个类还没有被加载和连接，那就先进行加载和连接 假如类存在直接父类，并且这个父类还没有被初始化，那就先初始化直接父类 假如类中存在初始化语句，那就依次执行这些初始化语句 ​ 类初始化的时机 ​ Java对类的使用方式可分为两种 主动使用 被动使用 ​ 所有的Java虚拟机实现必须要在每个类或接口被Java程序”首次主动使用“时才初始化它们 ​ 主动使用（七种，重要） 创建类的实例（new一个实例） 访问某个类或接口的静态变量，或者对该静态变量赋值 调用类的静态方法 反射（如Class.forName(“com.test.Test”)） 初始化该类的子类 Java虚拟机启动时被标明为启动类的类（包含main（）方法的类） JDK1.7开始提供的动态语言支持 ​ 除了上述七种情况，其他情况都认为是对类的被动使用，因此都不会导致类的初始化 ​ 当Java虚拟机初始化一个类时，要求它的所有父类都已经被初始化，但这条规则不适用于接口。 在初始化一个类时，并不会先初始化它所实现的接口 在初始化一个接口时，并不会先初始化它的父接口 ​ 因此，一个父接口并不会因为它的子接口或者实现类的初始化而初始化。只有当程序首次使用特定接口的静态变量时，才会导致该接口的初始化。 ​ 只有当程序访问的静态变量或静态方法确实在当前类或当前接口中定义时，才可以认为是对类或接口的主动使 5. 类的实例化 为新的对象分配内存 为实例变量赋默认值 为实例变量赋正确的初始值 Java编译器为它编译的每一个类都至少生成一个实例初始化方法，在Java的class文件中，这个实例初始化方法被称为“”。针对源代码中每一个类的构造方法，Java编译器都产生一个方法。 Some Cases/** * 类的初始化 * 虚拟机参数 -XX:+&lt;option&gt; 表示开启 &lt;option&gt; 选项 * -XX:-&lt;option&gt; 表示关闭 &lt;option&gt; 选项 * -XX:&lt;option&gt;=&lt;value&gt; 表示给 &lt;option&gt; 选项赋值 * -XX:+TraceClassLoading 用于追踪类的加载信息并打印出来 * -XX:+TraceClassUnLoading 用于追踪类的卸载信息并打印出来 * * @author charles * @date 2020/2/19 10:40 */ public class MyTest1 &#123; public static void main(String[] args) &#123; /* 对于静态字段来说,只有直接定义了该字段的类才会被初始化 str是在MyParent1中被定义,所以 MyChild1.str是对类 MyParent1 的主动使用, 所以类 MyParent1 会被初始化 */ System.out.println(MyChild1.str); /* str2 是在 MyChild1 中被定义,所以类 MyChild1 会被初始化 初始化一个类的子类时,父类也会被初始化(主动使用) */ System.out.println(MyChild1.str2); &#125; &#125; class MyParent1 &#123; public static String str = \"hello world\"; static &#123; System.out.println(\"MyParent1 static block\"); &#125; &#125; class MyChild1 extends MyParent1 &#123; public static String str2 = \"welcome\"; static &#123; System.out.println(\"MyChild1 static block\"); &#125; &#125; /** * 定义常量的类的初始化: * 常量在编译阶段会存入到调用这个常量的方法的类的常量池中, * 本质上调用类并没有直接引用到定义常量的类,因此并不会触发定义常量类的初始化 * 反编译 javap -c com.charles.jvm.classloader.MyTest2 * 助记符: * ldc:表示将int,float或是String类型的常量值从常量池中推送至栈顶 * bipush:表示将单字节(-128~127)的常量值从常量池中推送至栈顶 * sipush:表示将短整型(-32768~32767)的常量值从常量池中推送至栈顶 * iconst_i:i属于(-1~5)表示将int型的数字i从常量池中推送至栈顶 * * @author charles * @date 2020/2/19 11:21 */ public class MyTest2 &#123; public static void main(String[] args) &#123; /* 这里常量 MyParent2.STR 存放到了类 MyTest2 的常量池中, 之后 MyTest2 与 MyParent2 就没有任何关联了 甚至,我们可以将 MyParent2 的class文件删除 */ System.out.println(MyParent2.STR); &#125; &#125; class MyParent2 &#123; public static final String STR = \"hello world\"; static &#123; System.out.println(\"MyParent2 static block!\"); &#125; &#125; //反编译结果如下 D:\\Develop\\Java\\JavaProject\\JVMStudy\\build\\classes\\java\\main&gt;javap -c com.charles.jvm.classloader.MyTest2 Compiled from \"MyTest2.java\" public class com.charles.jvm.classloader.MyTest2 &#123; public com.charles.jvm.classloader.MyTest2(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: return public static void main(java.lang.String[]); Code: 0: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #4 // String hello world 5: invokevirtual #5 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return &#125; /** * 当一个常量的值并非编译期间可以确定的,那么其值就不会被放到调用类的常量池中 * 这时在程序运行时,会导致主动使用这个常量所在类,显然会导致这个类被初始化 * * @author charles * @date 2020/2/20 10:24 */ public class MyTest3 &#123; public static void main(String[] args) &#123; System.out.println(MyParent3.STRING); &#125; &#125; class MyParent3 &#123; public static final String STRING = UUID.randomUUID().toString(); static &#123; System.out.println(\"MyParent3 static block\"); &#125; &#125; /** * 创建类的实例,主动使用 * 对于数组实例来说,其类型是由JVM在运行期间动态生成的, * 表示为[Lcom.charles.jvm.classloader.MyParent4这种形式 * 动态生成的类型其父类就是Object * 对于数组来说,JavaDoc经常将构成数组的元素为Component,实际上就是将数组降低一个维度后的类型 * 助记符: * anewarray:表示创建一个引用类型的数组,并将其引用值压入栈顶 * newarray:表示创建一个指定的原始类型的数组,并将其引用值压入栈顶 * * @author charles * @date 2020/2/20 10:33 */ public class MyTest4 &#123; public static void main(String[] args) &#123; /* 首次主动使用才会初始化 */ MyParent4 p1 = new MyParent4(); MyParent4 p2 = new MyParent4(); /* 类的数组的实例,不是对类的主动使用 */ MyParent4[] parent4s = new MyParent4[2]; &#125; &#125; class MyParent4 &#123; static &#123; System.out.println(\"MyParent4 static block\"); &#125; &#125; /** * 当一个接口在初始化时,并不都要求其父接口完成初始化 * 只有当真正使用到父接口的时候(如引用到接中的常量时),才会初始化 * * @author charles * @date 2020/2/20 11:00 */ public class MyTest5 &#123; public static void main(String[] args) &#123; System.out.println(MyChild5.B); &#125; &#125; interface MyParent5 &#123; /** * 接口中的属性,默认为public static final */ int A = 5; &#125; interface MyChild5 extends MyParent5 &#123; int B = new Random().nextInt(); &#125; /** * @author charles * @date 2020/2/20 11:31 */ public class MyTest6 &#123; public static void main(String[] args) &#123; /* 调用了类Singleton中的静态方法,为主动使用,类Singleton被初始化 */ Singleton singleton = Singleton.getInstance(); System.out.println(\"counter1:\" + Singleton.counter1); System.out.println(\"counter2:\" + Singleton.counter2); &#125; &#125; class Singleton &#123; /** * 初始化counter1为1 */ public static int counter1 = 1; /** * 按顺序进行初始化,构造函数执行后,counter1=4,counter2=3 */ private static Singleton singleton = new Singleton(); /** * 然后counter2又被赋值为0 */ public static int counter2 = 8; private Singleton() &#123; /* counter1在前面已经被初始化为1,所以counter1=1+3 */ counter1 += 3; /* 准备阶段的意义 因为准备阶段,整型的默认值为0 所以counter2=0+3 */ counter2 += 3; &#125; public static Singleton getInstance() &#123; return singleton; &#125; &#125;","permalink":"http://Charles-xcz.github.io/2020/02/29/JVM学习(1)——类加载、连接与初始化/","photos":[]},{"tags":[{"name":"多线程","slug":"多线程","permalink":"http://Charles-xcz.github.io/tags/多线程/"},{"name":"volatile","slug":"volatile","permalink":"http://Charles-xcz.github.io/tags/volatile/"}],"title":"并发编程之——volatile","date":"2020/01/29","text":"1. volatile特征 volatile是Java虚拟机提供的轻量级同步机制 1. 保证可见性 某一线程修改了一个变量值并写回主内存后，会马上通知其它使用该变量的线程进行修改 2. 不保证原子性3. 禁止指令重排volatile实现禁止指令重排优化，从而避免多线程环境下程序出现乱序执行的现象。 先了解一个概念，内存屏障（Memory Barrier）又称内存栅栏，是一个CPU指令，它的作用有两个： 保证特定操作的执行顺序 保证某些变量的内存可见性（利用该特性实现volatile的内存可见性） ​ 由于编译器和处理器都能执行指令重排优化。如果在指令间插入一条Memory Barrier则会告诉编译器和CPU，不管什么指令都不能和这条Memory Barrier指令重排序，也就是说通过插入内存屏障禁止在内存屏障前后的指令执行重排序优化。 ​ 内存屏障另外一个作用是强制刷出各种CPU的缓存数据，因此任何CPU上的线程都能读取到这些数据的最新版本。（保证可见性） ​ 对volatile变量进行写操作时，会在写操作后加入一条store屏障指令，将工作内存中的共享变量值刷新回主内存中。 ​ 对volatile变量进行读操作时，会在读操作后加入一条load屏障指令，从主内存中读取共享变量。 想要了解volatile特性的具体含义，我们先来了解一下JMM。 2. JMM​ JMM（Java内存模型 Java Memory Model，简称JMM）本身是一种抽象的概念并不真实存在，它描述的是一组规则或规范，通过这组规范定义了程序中各个变量（包括实例字段，静态字段和构成数组对象的元素）的访问方式。 ​ JMM关于同步的规定： 线程解锁前，必须把共享变量的值刷新回主内存 线程加锁前，必须读取主内存的最新值到自己的工作内存 加锁解锁是同一把锁 ​ 由于JVM运行程序的实体是线程，而每个线程创建时JVM都会为其创建一个工作内存（有些地方称为栈空间），工作内存是每个线程的私有数据区域。 ​ 而Java内存模型中规定所有变量都存储在主内存，主内存是共享内存区域，所有线程都可以访问，但线程对变量的操作（读取赋值等）必须在工作内存中进行。 ​ 线程操作变量时，首先要将变量从主内存拷贝的自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量，各个线程中的工作内存中存储着主内存中的变量副本拷贝，因此不同的线程间无法访问对方的工作内存。 ​ 因此，线程间的通信（传值）必须通过主内存来完成，其简要访问过程如下图： JMM的三大特性 可见性 通过前面对JMM的介绍，我们知道 各个线程对主内存中共享变量的操作都是各个线程拷贝到自己的工作内存进行操作后再写回到主内存中的。 这就可能存在一个线程A修改了共享变量x的值但还未写回主内存时，另外一个线程B又对主内存中同一个共享变量X进行操作，但此时A线程工作内存中共享变量x对线程B来说并不可见，这种工作内存与主内存同步延迟现象就叫作可见性问题 。 原子性 不可分割性，完整性，也即某个线程正在做着某个具体的业务时，中间不可以被加塞或者被分割。需要整体完整，要么同时成功要么同时失败。 volatile不能保证原子性 如何解决原子性问题？ ​ 加synchronized锁 ​ 使用juc下的原子类，例如AtomicInteger原子整型 有序性 计算机在执行程序时，为了提高性能，编译器和处理器的常常会对指令做重排，一般分以下3种 ​ 指令重排，在单线程环境里，要能确保程序最终执行结果和代码顺序执行的结果是一致的。 ​ 处理器在进行重排序时必须要考虑指令之间的数据依赖性 ​ 但是在多线程环境中，线程交替执行，由于编译器优化重排的存在，两个线程中使用的变量能否保证一致性是无法确定的，结果无法预测。 3. 程序示例seek() 方法， number不加volatile修饰时，会在while(myData.number == 0)处死循环 加volatile修饰，程序正常执行，证明了volatile的可见性：当某一线程修改了一个变量值并写回主内存后，会马上通知其它使用该变量的线程进行修改。 atomic() 方法， 加了volatile的情况下，number的输出结果依然小于20000，这就是不能保证原子性 atomicInteger结果为2000，AtomicInteger保证原子性 class MyData &#123; //int number = 0; volatile int number = 0; public void addTo60() &#123; this.number = 60; &#125; public void addPlusPlus() &#123; this.number++; &#125; AtomicInteger atomicInteger = new AtomicInteger(); public void addAtomic() &#123; atomicInteger.getAndIncrement(); &#125; &#125; public class VolatileDemo01 &#123; /** *验证可见性方法 */ public void seek() &#123; MyData myData = new MyData(); new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + \":come in\"); //加休息1s,为了确保main线程进入循环时number为0 try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; myData.addTo60(); System.out.println(Thread.currentThread().getName() + \":update number to \" + myData.number); &#125;, \"AAA\").start(); while (myData.number == 0) &#123; &#125; System.out.println(Thread.currentThread().getName() + \"is over\"); &#125; /** *验证原子性方法 */ public void atomic() &#123; MyData myData=new MyData(); for (int i = 0; i &lt; 20; i++) &#123; new Thread(() -&gt;&#123; for (int j = 0; j &lt; 1000; j++) &#123; myData.addPlusPlus(); myData.addAtomic(); &#125; &#125;,String.valueOf(i)).start(); &#125; //需要等待上面20个线性计算完成后,再用main线程取得最终结果,看看是多少 //因为默认有两个线程,main线程和后台gc线程 while (Thread.activeCount() &gt; 2) &#123; Thread.yield(); &#125; System.out.println(Thread.currentThread().getName()+\"finally number value:\"+myData.number); System.out.println(Thread.currentThread().getName()+\"finally atomicInteger value:\"+myData.atomicInteger); &#125; &#125; 3. 禁止指令重排作用场景​ 单例模式DCL DCL（Double Check Lock）机制不一定100%线程安全，原因是指令重排序的存在，加入volatile可以禁止指令重排序 ​ 原因在于某一个线程执行到第一次检测，读取到的instance不为null时，instance的引用对象可能没有完成初始化。 ​ instance=new SingletonDemo()；可以分为以下3步完成（伪代码） memory = allocate(); //1.分配对象内存空间 instance(memory); //2.初始化对象 instance = memory; //3.设置instance指向刚分配的内存地址，此时instance！=null ​ 由于步骤2和步骤3不存在数据依赖关系，而且无论重排前还是重排后程序的执行结果在单线程中并没有改变，因此这种重排优化是允许的。 memory=allocate(); //1.分配对象内存空间 instance=memory(); //3.设置instance指向刚分配的内存地址，此时instance!=null，但是对象还没有初始化完成！ instance(memory); //2.初始化对象 ​ 但是指令重排只会保证串行语义的执行的一致性（单线程），但并不会关心多线程间的语义一致性。 ​ 所以当一条线程访问instance不为null时，由于instance实例未必已初始化完成，也就造成了线程安全问题。 关于AtomicInteger类如何保证原子性，参看CAS的原理。","permalink":"http://Charles-xcz.github.io/2020/01/29/并发编程之-volatile/","photos":[]},{"tags":[{"name":"红黑树","slug":"红黑树","permalink":"http://Charles-xcz.github.io/tags/红黑树/"},{"name":"数据结构","slug":"数据结构","permalink":"http://Charles-xcz.github.io/tags/数据结构/"}],"title":"什么是红黑树？","date":"2019/12/10","text":"1. 定义红黑树是满足下列条件的二叉查找树： 每个节点都带有红色或黑色。节点的颜色由以下规则确定： 根节点是黑色的。 所有叶节点都是黑色的。 在沿着从根出发的任何路径上都不允许出现两个连续的红色节点，即：“红色”结点的两个子结点都是“黑色”的。 从任一节点到其每个子孙叶子节点的所有简单路径都包含相同数目的黑色节点（简称黑色高度） 节点X的黑色高度：从节点X到其子孙叶子节点的简单路径中的黑色链的数量。 红黑树的黑色高度：根节点的黑色高度（称为：根节点的阶）红黑树的两种不同定义： 《算法导论》：叶子节点是指，扩充外部叶结点。即叶子节点为空的“黑色”节点 - 可以认为是2-3-4树的二叉树实现 《程序员实用算法》：数据只存储在叶子节点中，内部节点只用于引用； 示例: 《算法导论》中的红黑树,，黑色高度为2。 《程序员实用算法》中的红黑树，黑色高度为2。加粗为黑色结点本文基于《算法导论》的定义介绍。 2. 红黑树 与 2-3-4树红黑树，可等价转化为2-3-4树。 为了更好的理解红黑树，先看一下2-3-4树 2.1 2-3-4树介绍2-3-4树： 2-3-4树： 是二叉查找树的扩展 树中每个节点中有1个或2个或3个关键字，节点内部是有序的。 2-节点：有1个关键字，2个孩子 3-节点：有2个关键字，3个孩子 4-节点：有3个关键字，4个孩子 具有很好的平衡性：所有叶子节点的深度相同。 2-3-4树的查找插入B结点插入结点H 注意：在插入结点过程中，按照自顶向下的方式进行访问，当发现4-节点时，进行分裂。 即：插入结点时在遍历查找插入位置的路线上，凡是遇到4-结点，就对其进行分裂 现在，自顶向下构造一棵2-3-4树 2.2 二叉树来实现2-3-4树2-3-4树中有三类节点： 2-节点，3-节点和4-节点 对于3-节点和4-节点，利用红色链来绑定“内部”节点 红色链所指向的节点为红色节点（红色链下方的结点） 2-节点不变 3-节点变为用红色链连接的两个二叉树节点，指向外部孩子节点的指针为3个，数量不变。 4-节点转化为三个用红色链连接起来的二叉树节点，指向外部孩子节点的指针为4个，数量不变。 这样，2-3-4树就转化成了二叉树。但是，可以看到，2-3-4树对应的二叉树并不唯一，哪种才是等价的红黑树呢？ 2-3-4树的2-节点和4-节点变成成二叉树节点都是唯一的情况，3-节点呢？我们人为的规定，转换成左分支的情况，（左孩子节点小于父节点，二叉查找树的性质）并且在插入新节点的过程中，产生右分支的时候我们需要把它左旋成为左分支情况。这样，2-3-4树就对应成了唯一的二叉树，即红黑树。（红色链连接代表着2-3-4树节点内部的连接，红色链下方的节点表示红色节点） 那么，现在还剩下一个问题，2-3-4树插入节点过程中的4-节点分裂，对应着二叉树怎样的变化呢？ 2-3-4树中，双亲为2-节点时，4-节点的分裂： 2-3-4树4-节点分裂对应着二叉树的颜色向上翻转，当翻转后出现，右分支情况的3-节点时，旋转成左分支情况2-3-4树中，双亲为3-节点时，4-节点的分裂：在对应二叉树中，同样可以用颜色翻转和旋转等价实现。 当反转后，出现两个红色节点连续，显然不满足红黑树的定义，要进行旋转，旋转规则类似与AVL树失衡的旋转处理。 下面的两个旋转情况，和AVL树LL失衡，LR失衡旋转情况相同 3.总结：红黑树，本质上是2-3-4树两类基本操作： 颜色翻转 实质上为4-节点分裂 当某个结点的两个孩子结点都为红色时 将两个红色孩子结点和其黑色双亲结点的颜色翻转旋转 避免出现连续的两条红色链；避免出现单个的红色右链。 出现右的红色链时：对于右的红色链，进行左旋处理 有连续两个红色链时： 依据两个连续的红色链的形状，进行相应的旋转处理（类似AVL树的失衡旋转规则） 看道小试题， 从空树出发，根据待插入的关键字序列 {03,02,01,04,05,06,07,10,09,08}.构建红黑树。 仔细体会一下红黑树的构建过程。 可以画出对应2-3-4树的插入构建过程和红黑树对比加深理解。（节点依次插入，树未发生翻转变化时省略了重复画图）注意：将红色链指向(下方)的节点定义为红色节点，不要迷惑于红色节点的变化","permalink":"http://Charles-xcz.github.io/2019/12/10/聊聊红黑树/","photos":[]},{"tags":[{"name":"网络","slug":"网络","permalink":"http://Charles-xcz.github.io/tags/网络/"}],"title":"距离向量路由选择","date":"2019/11/29","text":"​ 距离向量路由选择是通过对Bellman-Ford算法进行适当修改，找到任意两结点之间的最短路径。 ​ 先介绍一下Bellman-Ford算法： 1 Bellman-Ford算法​ 这个算法基于这样一个事实，如果结点 i 的所有邻站都知道到结点的最短距离，那么求结点 i 和结点 j 之间的最短距离就可以用结点 i 到每个邻站之间的距离分别加上该邻站到结点j的最短距离，然后再从得数中选择最小的一个。 用以下步骤为每个结点创建一个最短距离表 : 1) 结点和它自己之间的最短距离和代价被初始化为0。 2) 一个结点和任何其他结点之间的最短距离被设置为无穷大。一个结点和其他任何结点之间的代价应当给定(如果两个节点之间没有直接连接，可设置为无穷大)。 3) 然后循环执行 算法Dij = min{(ci1+D1j),(ci2+D2j),……..(ciN+DNj)} 2 距离向量路由选择算法1) 在距离向量路由选择中，代价通常就是跳数（即在到达终点之前通过了多少个网络）。因此任意两个邻站之间的代价被设置为1。 2) 每当路由器从它的邻站那里接收到一些信息时，它就要异步地更新自己的路由表。换言之，每个路由器只执行了整个Bellman-Ford算法中的一部分。这个处理过程是分布式的。 3) 在路由器更新了自己的路由表之后，应当将结果发送给它的所有邻站，以便这些邻站也能更新它们的路由表。 4) 每个路由器至少应当保存每条路由的三个信息：目的网络、代价和下一跳。我们称完整的路由表为Table，表中的第i行为Tablei第i行的三个列分别为Tablei.dest，Tablei.cost和Tablei.next。 5) 我们把来自邻站的一条路由信息称为一个R（记录），它只包含了两个信息：R.dest和R.cost。在收到的记录中不包含下一跳信息，因为下一跳就是发送方的源地址。 3 计数到无穷大​ 距离向量路由的缺点是：好消息传得快，坏消息传得慢。要想让路由选择协议能够正常工作，如果一条链路中断了（代价变为无穷大），那么其他所有路由器都应当立刻获知这一情况，但是在距离向量路由选择中，这是要花费一些时间的。这个问题就称为计数到无穷大（count to infinity）。需要经过多次更新才能使所有的路由器都把这条中断链路的代价记录为无穷大。 二结点循环问题: 为了解决这种不稳定性的几种方法： 1) 定义无穷大：距离向量协议一般把16定义为无穷大，即16跳为不可达，但是这也意味着距离向量不能用于大系统。在各个方向上，网络的大小都不能超过15跳。 2) 分割范围：如果结点B根据其路由表认为到达X的最佳路由要经过A，那么它就不需要再把到X的路由通告给A了，因为这个信息就是从A来的（A已经知道了）。从结点A得到信息，修改后再发回给A，这就是产生混乱的根源。所以，结点B在发送路由表给A之前要删除路由表中下一跳为A的路由信息。在这种情况下，结点A保留到X的距离为无穷大。在此之后，当结点A将其路由表发送给B时，结点B也就更正了它的路由表。系统在第一次更新后就变稳定了，因为结点A和B都知道了X是不可达的。 3) 分割范围和毒性逆转：使用分割范围策略有一个缺点。通常，距离向量协议使用一个计时器，若长时间没有关于某个路由的消息，就要从路由表中删除这个路由。在前面描述的场景中，当结点B在它给A的通告中删除了到X的路由时，结点A并不能猜出这是由于分割范围策略(因为信息的来源是A)，还是因为B最近一直都没有收到有关X的任何消息。分割范围策略可以与毒性逆转（poison reverse）策略组合起来使用。结点B可以仍然通知关于X的数值，但如果信息源是A，就把距离换成为无穷大(16)作为一种警告：“不要使用这个数值，我所知道的关于这条路由的信息来自于你。” 三结点不稳定性​ 分割范围和毒性逆转可以用于避免二结点的不稳定性，但如果是三个结点之间，稳定性仍然无法保证。","permalink":"http://Charles-xcz.github.io/2019/11/29/路径向量路由选择/","photos":[]},{"tags":[{"name":"算法","slug":"算法","permalink":"http://Charles-xcz.github.io/tags/算法/"},{"name":"kmp","slug":"kmp","permalink":"http://Charles-xcz.github.io/tags/kmp/"}],"title":"模式匹配—>KMP算法","date":"2019/11/19","text":"引言​ 场景：在字符串：“fffffab cfe defe” 中查找字符串 “ff”。 ​ 被查找的字符串称之为：主串或目标串T ; ​ 想要查找的字符串”ff”称之为：字串或模式串P。 ​ 朴素的模式匹配在匹配过程中需要进行回溯，因而会发生多次重复比较，匹配效率低。故而，需要对字符串查找算法进行优化。 ​ 字符串查找算法中，最著名的算法之一：KMP算 法（Knuth-Morris-Pratt) ​ 它是精确字符串匹配算法（区别于模糊匹配）。 ​ – 目标字符串中无需进行回溯。（比朴素的模式匹配算法快）​ – 模式字符串的移动方向：从目标字符串的第一个字符 开始，朝目标字符串的尾部方向移动搜索匹配子串。 KMP算法1 KMP​ 注意：为了方便，KMP算法中，数组下标一般从1开始。 ​ KMP算法的设计初衷： 希望能在匹配过程中，目标串T中的字符匹配是一直向右前进的，而不会出现向左的回溯。 下面看两个例子 例1：当模式串中无重复时 因为模式串中无重复，因为T[1]=P[1]，T[2]=P[2]，显然T[2]!=P[1]。即第二轮比较多余 同理，2，3，4，5轮的匹配都是多余的。 例2：模式串P中有重复 从图上可以看出2，3，4，5轮，目标串匹配字符i的回溯都是多余的。我们可以直接从1跳到6。 why？？为什么可以跳？怎么跳？ 注意观察模式串字符的规律：这里我们要利用模式串P自身的重复。 下面继续放一些示例： 关注： 匹配失败，是否发生在P的第一个字符处？ ​ P中是否有重复模式？ 分析总结： ​ 前两种情况容易得出： ​ 若当前轮匹配在与P[1]比较就失败，那么 下一轮应该是比较T[i+1]和P[1] ​ 若P中在当前轮成功匹配的子串的后缀与子串的前缀无重复模式，那么下一轮应该是比较T[i]和P[1] ​ 第三种情况： ​ 若P中在当前轮成功匹配的子串的后缀与子串的前缀有重复模式，那么下一轮应该是比较T[i]和P[next[j]] ​ next[j]:在模式串P的下标 j 处失配后，下一轮比较的模式串P的下标，用next数组记录模式串P每个位置失配后下一轮应该比较的位置。 那么next[j] = ？ 在上图 Case1 中，P中无重复模式，下轮比较T[i]和P[1]，下轮比较的模式串下标为1，即next[j]=1; ​ Case2中，P[1]就失配，下轮比较T[i+1]和P[1]，我们用next[j]=0来表示这种情况，代表着在模式串P开头处即失配，目标串下标i向后移动一位。我们把下标为0来代表这种情况，这也是为什么KMP算法下标从1开始计算的原因。 ​ Case3和Case4: 在P[j]处失配，设存在k|1&lt;k&lt;j 使得”P[1]…..P[k-1]“=”P[j-k+1]….P[j-1]” 即模式串P的前k-1位子串与从P[j]处往前k-1位子串相同，即P中在当前轮成功匹配的子串的后缀与子串的前缀有重复模式，则下轮比较从k开始，next[j]=k。 所以： 2 KMP算法思想总结 将模式串P自身的重复规律保存到next数组中 匹配过程：若某轮匹配失败，则利用next数组分 别计算下一轮匹配时目标串和模式串的开始位置若是T[i]≠P[j]导致当前轮的匹配失败，则按照下列规则 开始下一轮匹配： 若next[j] ≠ 0，则将T[i..]与P[next[j]..]匹配； 若next[j]==0，则将T[(i+1)..]与P[1..]匹配。","permalink":"http://Charles-xcz.github.io/2019/11/19/模式匹配——KMP/","photos":[]}]}