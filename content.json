{"meta":{"title":"Charles","subtitle":null,"description":null,"author":"Charles","url":"http://Charles-xcz.github.io","root":"/"},"posts":[{"tags":[{"name":"JVM","slug":"JVM","permalink":"http://Charles-xcz.github.io/tags/JVM/"}],"title":"JVM学习(6)——常见JVM参数和内存异常","date":"2020/04/19","text":"1. JVM参数1. 参数类型 标配参数 -version -help -showversion x参数 -Xint：解释执行 -Xcomp：第一次使用就编译成本地代码 -Xmixed：混合模式（默认） xx参数 Boolaen类型 -XX:+/- 表示开启或关闭某个属性值 例：-XX: +PrintGCDetails开启打印GC收集细节 ​ -XX:+UseSerialGC 开启串行垃圾回收器 KV设值参数 -XX:属性key=属性值value 例：-XX:MataspaceSize=128m ​ -XX:MaxTenuringThreshold=15 注意：-Xms和-Xmx参数是xx参数，-XX:InitialHeapSize和-XX:MaxHeapSize的简化 2. 查看参数 使用jps+jinfo 在命令行运行 jps -l 查看运行中的进程编号 ​ 然后运行命令 jinfo -flag &lt;配置项&gt; &lt;进程编号&gt; 查看该进程该配置的信息。 ​ jinfo -flags &lt;进程编号&gt; 查看该进程所有属性配置 通过JVM参数查看 java -XX:+PrintFlagsInitial 查看所有初始的参数 java -XX:+PrintFlagsFinal -version 查看当前当前参数 =是未被修改的参数，:=代表被修改后的参数 -XX:PrintCommandLineFlags 方便产看使用的垃圾回收器类型 3. 常用参数-Xms 初始内存大小，默认为物理内存的1/64，等价于 -XX:initialHeapSize -Xmx 最大分配内存，默认为物理内存的1/4，等价于-XX:MaxHeapSize -Xss 设置单个线程的大小，一般默认为512k~1024k，等价于-XX:ThreadStackSize -Xmn 设置年轻代的大小，一般不调节 -XX:MetaspaceSize 设置元空间大小 元空间的本质和永久代类似，都是对JVM 规范中方法区的实现。 不过元空间与永久代最大的区别在于，元空间并不在虚拟机中，而是使用本地内存。 因此，默认情况下，元空间的大小仅受本地内存限制。 -XX:+PrintGCDetails 打印GC详细信息 -XX:SurvivorRatio 配置新生代中Eden和S0/S1空间的比例 默认为8:1:1，若设 -XX:SurvirorRatio=4，即Eden:S0:S1=4:1:1 -XX:NewRatio 配置老年代和新生代的空间比例，默认为2:1 -XX:MaxTenuringThreshold 设置垃圾的最大年龄，默认15 2. 内存错误 java.lang.StackOverflowError 栈空间溢出：方法的递归调用深度超出栈空间的内存。 java.lang.OutOfMemoryError: java heap space 堆空间溢出：创建了对象占用超出了堆空间(新生代空间)限制。 java.lang.OutOfMemoryError: GC overhead limit exceeded GC回收时间过长时会抛出OutOfMemroyError 时间长的定义是，超过98%的时间用来做GC并且回收了不到2%的堆内存。 连续多次GC都只回收了不到2%的极端信况下才会抛出该错误。 如果不抛出GC overhead limit 错误会发生什么荐况呢？ 那就是GC清理的这么点内存很快会再次被填满，迫使GC再次执行。 这样就形成恶性循环，CPU占用一直是100%，而GC却没有任何成果。 /** * -Xmx5m -Xms5m -XX:+PrintGCDetails */ public static void gcOverhead() { int i = 0; List&lt;String> list = new ArrayList&lt;>(); try { while (true) { list.add(String.valueOf(++i).intern()); } } catch (Throwable e) { e.printStackTrace(); throw e; } } java.lang.OutOfMemoryError: Direct buffer memory 导致原因： 写NIO程序时经常使ByteBuffer来读或者写入数据，这是一种基于通道（Channel）与缓冲区（Buffer）的I/O方式， 它可以使Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的DirectByteBuffer对象作为这块内存的引用进行操作。 这样能在一些场景中显著提高性能，因为避免了在Java堆和 Native堆中来回复制数据。 ByteBuffer.allocate(capability) 是分配JVM堆内存，属GC管辖范围，由于需要拷贝，所以速度相对较慢。 ByteBuffer.allocteDirect(capability) 是分配OS本地内存，不属于GC管辖范围，由于不需要内存拷贝所以速度相对较快。 但如果不断分配本地内存，堆内存很少使用，都么JVM就不需要执行GC，DirectByteBuffer对象们就不会被回收，这时候堆内存充足，但本地内存可能已经使用光了，再次尝试分配本地内存就会出0utOfMemoryError，那程序就直接崩溃了。 /** * -XX:MaxDirectMemorySize=5m * 结果抛出 Exception in thread \"main\" java.lang.OutOfMemoryError: Direct buffer memory */ public class DirectBufferMemoryDemo { public static void main(String[] args) { System.out.println(\"配置的maxDirectMemory:\" + (sun.misc.VM.maxDirectMemory() / (double) 1024 / 1024) + \"MB\"); ByteBuffer bb = ByteBuffer.allocateDirect(6 * 1024 * 1024); } } java.lang.OutOfMemoryError: unable to create new native thread 高并发请求服务器时，经常出现如下景常：java.Lang.OutOfMemoryError:unable to create new native thread 该native thread异常与对应的平台有关 导致原因： 你的应用创建了太多线程了，一个应用进程创建多个线程，超过系统承载极限。 你的服务器并不允许你的应用程科序创建这么多进程，Linux系统默认充许单个进程可以创建的线程数是1024个，你的应用创建超过这个数量，就会报unable to create new native thread异常。 解决办法： 想办法降低你应用程序创建线程的数量，分析应用是否真的需要创建这么多线程，如果不是，改代码将线程数降到最低。 对于有的应用，确实需要创建很多线程，远超过Linux系统的默认的1024个线程的限制，可以通过修改linux服务器配置，扩大Linux默认限制。 java.lang.OutOfMemoryError: Mataspace","permalink":"http://Charles-xcz.github.io/2020/04/19/JVM学习(6)——JVM参数和常见OOM异常/","photos":[]},{"tags":[{"name":"线程通信","slug":"线程通信","permalink":"http://Charles-xcz.github.io/tags/线程通信/"}],"title":"进程与线程及其通信方式","date":"2020/04/19","text":"1. 进程1.1 介绍进程，保存在磁盘上的程序运行以后，会在内存空间里形成一个独立的内存体。这个内存体有自己的地址空间，有自己的堆，上级挂靠单位是操作系统。操作系统会以进程为单位，分配系统资源（CPU时间片、内存等资源），进程是资源分配的最小单位。 1.2 进程的五种状态创建：进程在创建时需要申请一个空白PCB，向其中填写控制和管理进程的信息，完成资源分配。如果创建工作无法完成，比如资源无法满足，就无法被调度运行，把此时进程所处状态称为创建状态。 就绪：进程已经准备好，已分配到所需资源，只要分配到CPU就能够立即运行。 执行：进程处于就绪状态被调度后，进程进入执行状态。 阻塞：正在执行的进程由于某些事件（I/O请求，申请缓存区失败）而暂时无法运行，进程受到阻塞。在满足请求时进入就绪状态等待系统调用。 终止：进程结束，或出现错误，或被系统终止，进入终止状态。无法再执行 如果进程运行时间片使用完也会进入就绪状态。另外为用户观察需要，进程还有挂起和激活两种操作。挂起后进程处于静止状态进程不再被系统调用，对于操作是激活操作。 1.3 进程通信1）为什么要进程通信?1、数据传输一个进程需要将它的数据发送给另一个进程;2、资源共享多个进程之间共享同样的资源;3、通知事件一个进程需要向另一个或一组进程发送消息，通知它们发生了某种事件;4、进程控制有些进程希望完全控制另一个进程的执行(如Debug进程)，该控制进程希望能够拦截另一个进程的所有操作，并能够及时知道它的状态改变。基于以上几个原因，所以就有了进程间通信的概念，那么进程间通信的原理是什仫呢？目前有哪几种进程间通信的机制？他们是如何实现进程间通信的呢？ 2）进程间通信的原理每个进程各自有不同的用户地址空间,任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核,在内核中开辟一块缓冲区,进程1把数据从用户空间拷到内核缓冲区,进程2再从内核缓冲区把数据读走,内核提供的这种机制称为进程间通信机制。 3）进程通信的几种方式1、管道（Pipe）管道又名匿名管道，这是一种最基本的IPC机制，由pipe函数创建： 调用pipe函数时在内核中开辟一块缓冲区用于通信,它有一个读端，一个写端：pipefd[0]指向管道的读端，pipefd[1]指向管道的写端。所以管道在用户程序看起来就像一个打开的文件,通过read(pipefd[0])或者write(pipefd[1])向这个文件读写数据，其实是在读写内核缓冲区。 使用管道通信的过程： 父进程调用pipe开辟管道,得到两个文件描述符指向管道的两端。 父进程调用fork创建子进程,那么子进程也有两个文件描述符指向同一管道。 父进程关闭管道读端，子进程关闭管道写端。父进程可以往管道里写，子进程可以从管道里读，管道是用环形队列实现的，数据从写端流入从读端流出,这样就实现了进程间通信。 管道出现的四种特殊情况： 写端关闭，读端不关闭； 那么管道中剩余的数据都被读取后,再次read会返回0,就像读到文件末尾一样。 写端不关闭，但是也不写数据，读端不关闭；此时管道中剩余的数据都被读取之后再次read会被阻塞，直到管道中有数据可读了才重新读取数据并返回； 读端关闭，写端不关闭；此时该进程会收到信号SIGPIPE，通常会导致进程异常终止。 读端不关闭，但是也不读取数据，写端不关闭；此时当写端被写满之后再次write会阻塞，直到管道中有空位置了才会写入数据并重新返回。 使用管道的缺点： 两个进程通过一个管道只能实现单向通信，如果想双向通信必须再重新创建一个管道或者使用sockpair才可以解决这类问题； 只能用于具有亲缘关系的进程间通信，例如父子，兄弟进程。 2、命名管道（FIFO）上一种进程间通信的方式是匿名的，所以只能用于具有亲缘关系的进程间通信，命名管道的出现正好解决了这个问题。 FIFO不同于管道之处在于它提供一个路径名与之关联，以FIFO的文件形式存储文件系统中。 命名管道是一个设备文件，因此即使进程与创建FIFO的进程不存在亲缘关系，只要可以访问该路径，就能够通过FIFO相互通信。 命名管道的特点： 命名管道是一个存在于硬盘上的文件，而管道是存在于内存中的特殊文件。所以当使用命名管道的时候必须先open将其打开。 命名管道可以用于任何两个进程之间的通信，不管这两个进程是不是父子进程，也不管这两个进程之间有没有关系。 3、消息队列（Message Queue）消息队列就是消息的链表，位于内核中。消息队列中每个数据块都被认为是有一个类型，接收者进程接收的数据块可以有不同的类型值。消息队列是基于消息的，管道是基于字节流的，且消息队列的读取不一定是先入先出。 注意： 管道的生命周期是随进程的，只要该进程消亡了该管道就会随之消失。但是消息队列却是随内核的，即使该进程消亡了该内核中的消息队列是不会主动消失的，除非使用ipcrm -q + msg_id删除该消息队列，也可以使用ipcs -q查看系统中的消息队列。 4、信号量（Semaphore）什么是信号量？ 信号量的本质是一种数据操作锁，用来负责数据操作过程中的互斥，同步等功能。 信号量用来管理临界资源的。它本身只是一种外部资源的标识，不具有数据交换功能，而是通过控制其他的通信资源实现进程间通信。 可以这样理解，信号量就相当于是一个计数器。当有进程对它所管理的资源进行请求时，进程先要读取信号量的值：大于0，资源可以请求；等于0，资源不可以用，这时进程会进入睡眠状态直至资源可用。 当一个进程不再使用资源时，信号量+1(对应的操作称为V操作)，反之当有进程使用资源时，信号量-1(对应的操作为P操作)。对信号量的值操作均为原子操作。 为什么要使用信号量？ 为了防止出现因多个程序同时访问一个共享资源而引发的一系列问题，我们需要一种方法，它可以通过生成并使用令牌来授权，在任一时刻只能有一个执行线程访问代码的临界区域。 什么是临界区？什么是临界资源？ 临界资源：一次只允许一个进程使用的资源。临界区：访问临界资源的程序代码片段。 信号量的工作原理？ P(sv)：如果sv的值大于零，就给它减1；如果它的值为零，就挂起该进程的执行等待操作； V(sv)：如果有其他进程因等待sv而被挂起，就让它恢复运行，如果没有进程因等待sv而挂起，就给它加1； 举个例子，就是两个进程共享信号量sv，一旦其中一个进程执行了P(sv)操作，它将得到信号量，并可以进入临界区，使sv减1。而第二个进程将被阻止进入临界区，因为当它试图执行P(sv)时，sv为0，它会被挂起以等待第一个进程离开临界区域并执行V(sv)释放信号量，这时第二个进程就可以恢复执行了。 5、共享内存（Shared Memory）共享内存的特点： 共享内存是这五种进程间通信方式中效率最高的。但是因为共享内存没有提供相应的互斥机制，所以一般共享内存都和信号量配合起来使用。 为什么共享内存的方式比其他进程间通信的方式效率高？ 消息队列，FIFO，管道的消息传递方式一般为 ： 服务器获取输入的信息； 通过管道，消息队列等写入数据至内存中，通常需要将该数据拷贝到内核中； 客户从内核中将数据拷贝到自己的客户端进程中； 然后再从进程中拷贝到输出文件； 上述过程通常要经过4次拷贝，才能完成文件的传递。而共享内存只需要： 输入内容到共享内存区； 从共享内存输出到文件。 上述过程不涉及到内核的拷贝，这些进程间数据的传递就不再通过执行任何进入内核的系统调用来传递彼此的数据，节省了时间，所以共享内存是这五种进程间通信方式中效率最高的。 6、套接字（Socket）面说到的进程间的通信，所通信的进程都是在同一台计算机上的，而使用socket进行通信的进程可以是同一台计算机的进程，也是可以是通过网络连接起来的不同计算机上的进程。 套接字的特性由3个属性确定，它们分别是：域、类型和协议。 1、套接字的域 它指定套接字通信中使用的网络介质，最常见的套接字域是AF_INET，它指的是Internet网络。当客户使用套接字进行跨网络的连接时，它就需要用到服务器计算机的IP地址和端口来指定一台联网机器上的某个特定服务，所以在使用socket作为通信的终点，服务器应用程序必须在开始通信之前绑定一个端口，服务器在指定的端口等待客户的连接。另一个域AF_UNIX表示UNIX文件系统，它就是文件输入/输出，而它的地址就是文件名。 2、套接字类型 因特网提供了两种通信机制：流（stream）和数据报（datagram），因而套接字的类型也就分为流套接字和数据报套接字。这里主要讲流套接字。 流套接字由类型SOCK_STREAM指定，它们是在AF_INET域中通过TCP/IP连接实现，同时也是AF_UNIX中常用的套接字类型。流套接字提供的是一个有序、可靠、双向字节流的连接，因此发送的数据可以确保不会丢失、重复或乱序到达，而且它还有一定的出错后重新发送的机制。 与流套接字相对的是由类型SOCK_DGRAM指定的数据报套接字，它不需要建立连接和维持一个连接，它们在AF_INET中通常是通过UDP/IP协议实现的。它对可以发送的数据的长度有限制，数据报作为一个单独的网络消息被传输,它可能会丢失、复制或错乱到达，UDP不是一个可靠的协议，但是它的速度比较高，因为它并一需要总是要建立和维持一个连接。 3、套接字协议 只要底层的传输机制允许不止一个协议来提供要求的套接字类型，我们就可以为套接字选择一个特定的协议。通常只需要使用默认值。 2. 线程线程，有时被称为轻量级进程(Lightweight Process，LWP），是操作系统调度（CPU调度）执行的最小单位。 2.1线程通信1、共享变量方式 Synchronized、wait、notify Lock、Condition volatile CountDownLatch、CyclicBarrier、Semaphore 2、BlockingQueue参见《线程阻塞和阻塞队列》 3、管道通信public class PipedDemo { private final PipedInputStream inputStream1; private final PipedOutputStream outputStream1; private final PipedInputStream inputStream2; private final PipedOutputStream outputStream2; public PipedDemo(){ inputStream1 = new PipedInputStream(); outputStream1 = new PipedOutputStream(); inputStream2 = new PipedInputStream(); outputStream2 = new PipedOutputStream(); try { inputStream1.connect(outputStream2); inputStream2.connect(outputStream1); } catch (IOException e) { e.printStackTrace(); } } /**程序退出时，需要关闭stream*/ public void shutdown() throws IOException { inputStream1.close(); inputStream2.close(); outputStream1.close(); outputStream2.close(); } public static void main(String[] args) throws IOException { PipedDemo demo =new PipedDemo(); new Thread(()->{ PipedInputStream in = demo.inputStream2; PipedOutputStream out = demo.outputStream2; for (int i = 0; i &lt; 10; i++) { try { byte[] inArr = new byte[2]; in.read(inArr); System.out.print(Thread.currentThread().getName()+\": \"+i+\" \"); System.out.println(new String(inArr)); while(true){ if(\"go\".equals(new String(inArr))) break; } out.write(\"ok\".getBytes()); } catch (IOException e) { e.printStackTrace(); } } }).start(); new Thread(()->{ PipedInputStream in = demo.inputStream1; PipedOutputStream out = demo.outputStream1; for (int i = 0; i &lt; 10; i++) { try { out.write(\"go\".getBytes()); byte[] inArr = new byte[2]; in.read(inArr); System.out.print(Thread.currentThread().getName()+\": \"+i+\" \"); System.out.println(new String(inArr)); while(true){ if(\"ok\".equals(new String(inArr))) break; } } catch (IOException e) { e.printStackTrace(); } } }).start(); } } 3. 进程线程的区别与联系1、区别 调度：线程作为调度和分配的基本单位，进程作为拥有资源的基本单位； 并发性：不仅进程之间可以并发执行，同一个进程的多个线程之间也可并发执行； 拥有资源：进程是拥有资源的一个独立单位，线程不拥有系统资源，但可以访问隶属于进程的资源。进程所维护的是程序所包含的资源（静态资源）， 如：地址空间，打开的文件句柄集，文件系统状态，信号处理handler等；线程所维护的运行相关的资源（动态资源），如：运行栈，调度相关的控制信息，待处理的信号集等； 系统开销：在创建或撤消进程时，由于系统都要为之分配和回收资源，导致系统的开销明显大于创建或撤消线程时的开销。但是进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个进程死掉就等于所有的线程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。 2、联系 一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程； 资源分配给进程，同一进程的所有线程共享该进程的所有资源； 处理机分给线程，即真正在处理机上运行的是线程； 线程在执行过程中，需要协作同步。不同进程的线程间要利用消息通信的办法实现同步。 4. 协程 协程，是一种比线程更加轻量级的存在，协程不是被操作系统内核所管理，而完全是由程序所控制（也就是在用户态执行）。这样带来的好处就是性能得到了很大的提升，不会像线程切换那样消耗资源。 子程序，或者称为函数，在所有语言中都是层级调用，比如A调用B，B在执行过程中又调用了C，C执行完毕返回，B执行完毕返回，最后是A执行完毕。所以子程序调用是通过栈实现的，一个线程就是执行一个子程序。子程序调用总是一个入口，一次返回，调用顺序是明确的。而协程的调用和子程序不同。 协程在子程序内部是可中断的，然后转而执行别的子程序，在适当的时候再返回来接着执行。 协程的特点在于是一个线程执行，那和多线程比，协程有何优势？ 极高的执行效率：因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显； 不需要多线程的锁机制：因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。","permalink":"http://Charles-xcz.github.io/2020/04/19/进程线程协程对比/","photos":[]},{"tags":[{"name":"代理模式","slug":"代理模式","permalink":"http://Charles-xcz.github.io/tags/代理模式/"}],"title":"设计模式——代理模式","date":"2020/03/13","text":"1. 基本介绍代理模式：为一个对象提供一个替身，以控制对这个对象的访问。即通过代理对象访问目标对象。 这样做的好处是：可以在目标对象实现的基础上，增强额外的功能操作，即扩展目标对象的功能。 被代理的对象可以是远程对象，创建开销大的对象或需要安全控制的对象。 代理模式主要有三种： 静态代理 动态代理（JDK代理、接口代理） CGLIB代理（可以在内存中动态的创建对象，而不需要实现接口，也属于动态代理的范畴）。 2. 静态代理2.1 基本介绍静态代理在使用时，需要定义接口或者父类，被代理对象（即目标对象）与代理对象一起实现相同的接口或者是继承相同父类。 2.2 实例可以把明星看作一个目标对象，经纪人则是代理对象。明星只负责表演节目，其他操作交由经纪人去做。 通过经纪人去访问明星，达到在目标对象实现的基础上，增强额外的功能操作，即扩展目标对象的功能。 静态代理实现： 定义一个接口：IStar 目标对象Star实现接口IStar 使用静态代理方式，就需要在代理对象StarProxy中也实现IStar 调用的时候通过调用代理对象的方法来调用目标对象。 特别提醒：代理对象与目标对象要实现相同的接口，然后通过调用相同的方法来调用目标对象的方法。 package proxy.staticproxy; public class Client { public static void main(String[] args) { //创建目标对象 Star star=new Star(); //创建代理对象 StarProxy starProxy = new StarProxy(star); //通过代理对象调用目标对象的操作 starProxy.perform(); } } package proxy.staticproxy; public interface IStar { void perform(); } package proxy.staticproxy; public class Star implements IStar { @Override public void perform() { System.out.println(\"明星表演节目...\"); } } package proxy.staticproxy; public class StarProxy implements IStar { /** * 目标对象,通过接口聚合. */ private IStar target; public StarProxy(IStar target) { this.target = target; } @Override public void perform() { System.out.println(\"经纪人:商谈,签约..等等操作\"); target.perform(); System.out.println(\"结束:结算\"); } } 2.3 优缺点 优点：在不修改目标对象的功能前提下，能通过代理对象对目标功能扩展。 缺点：因为代理对象需要与目标对象实现一样的接口，所以会有很多代理类3）一旦接口增加方法，目标对象与代理对象都要维护。 3. JDK代理3.1 基本介绍 代理对象，不需要实现接口，但是目标对象要实现接口，否则不能用动态代理； 代理对象的生成，是利用JDK的APl，动态的在内存中构建代理对象； 动态代理也叫做：JDK代理、接口代理 JDK中生成代理对象的API 代理类所在包：java.lang.reflect.Proxy JDK实现代理只需要使用newProxylnstance方法，但是该方法需要接收三个参数，完整的写法是： static Object newProxyInstance(Classloader loader, Class&lt;?>[] interfaces, InvocationHandler h) 3.2 实例将2.2的实例改成动态代理模式。 package proxy.dynamicproxy; public class Client { public static void main(String[] args) { //创建目标对象 IStar target = new Star(); //给目标对象创建代理对象 IStar proxyInstance = (IStar) new ProxyFactory(target).getProxyInstance(); //可以看到代理类为 class com.sun.proxy.$Proxy0 System.out.println(proxyInstance.getClass()); //通过代理对象,调用目标对象的方法 proxyInstance.perform(); } } package proxy.dynamicproxy; import java.lang.reflect.Proxy; public class ProxyFactory { /** * 维护一个目标对象 */ private Object target; public ProxyFactory(Object target) { this.target = target; } /** * 给目标对象生成一个代理对象,代理对象通过反射机制调用目标对象中的方法 * * @return 代理对象 */ public Object getProxyInstance() { /* 1. ClassLoader loader: 当前目标对象的类加载器 2. Class&lt;?>[] interfaces: 目标对象实现的接口类型 3. InvocationHandler h: 事件处理器,执行目标对象的方法时,会触发事件处理器, 会把当前执行的目标对象方法作为参数传给事件处理器. */ return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), (proxy, method, args) -> { System.out.println(\"代理开始~~~~\"); //反射机制调用目标对象的方法 Object returnVal = method.invoke(target, args); System.out.println(\"代理结束~~~~\"); return returnVal; }); } } package proxy.dynamicproxy; public interface IStar { void perform(); } package proxy.dynamicproxy; public class Star implements IStar { @Override public void perform() { System.out.println(\"明星表演节目...\"); } } 4. CGLIB代理4.1 基本介绍 静态代理和JDK代理模式都要求目标对象实现一个接口，但是有时候目标对象只是一个单独的对象，并没有实现任何的接口。这个时候可使用目标对象的子类来实现代理，这就是CGLIB代理。 CGLIB代理也叫作子类代理，它是在内存中构建一个子类对象从而实现对目标对象功能扩展，有些书也将CGLIB代理归属到动态代理。 CGLIB是一个强大的高性能的代码生成包，它可以在运行期扩展java类与实现java接口。它广泛的被许多AOP的框架使用，例如Spring AOP，实现方法拦截。 在AOP编程中如何选择代理模式： 目标对象需要实现接口，用JDK代理 目标对象不需要实现接口，用CGLIB代理 CGLIB包的底层是通过使用字节码处理框架ASM，来转换字节码并生成新的类。 CGLIB实现步骤： 引入CGLIB的jar包； 在内存中动态构建子类，注意代理的类不能是final，否则报错； 目标对象的方法如果为final/static，那么就不会被拦截，即无法通过CGLIB代理增强目标对象的final/static方法。 4.2 实例将2.2的实例改成CGLIB代理模式。 package cglib; public class Client { public static void main(String[] args) { Star star = new Star(); Star proxyInstance = (Star) new ProxyFactory(star).getProxyInstance(); proxyInstance.perform(); } } package cglib; import net.sf.cglib.proxy.Enhancer; import net.sf.cglib.proxy.MethodInterceptor; import net.sf.cglib.proxy.MethodProxy; import java.lang.reflect.Method; public class ProxyFactory implements MethodInterceptor { /** * 目标对象 */ private Object target; public ProxyFactory(Object target) { this.target = target; } /** * 为目标对象创建代理对象 * @return 代理对象 */ public Object getProxyInstance() { //1. 创建一个工具类 Enhancer enhancer = new Enhancer(); //2. 设置父类 enhancer.setSuperclass(target.getClass()); //3. 设置回调函数 enhancer.setCallback(this); //4. 创建子类对象,即代理对象 return enhancer.create(); } @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable { System.out.println(\"cglib代理模式~~\"); Object returnVal = method.invoke(target, objects); System.out.println(\"cglib代理结束~~\"); return returnVal; } } package cglib; /** * 不需要实现接口 */ public class Star { public void perform() { System.out.println(\"明星表演节目....\"); } } 5. JDK代理 VS CGLIB5.1 何时使用对于Spring AOP的实现： 如果目标对象实现了接口，默认情况下会采用JDK的动态代理实现AOP。 如果目标对象实现了接口，可以强制使用CGLIB实现AOP。 如果目标对象没有实现了接口，必须采用CGLIB库，Spring会自动在JDK动态代理和CGLIB之间转换。 5.2 实现区别 JDK动态代理只能对实现了接口的类生成代理，而不能针对类。 CGLIB是针对类实现代理，主要是对指定的类生成一个子类，覆盖其中的方法，并覆盖其中方法实现增强，但是因为采用的是继承，所以该类或方法最好不要声明成final， 对于final类或方法，是无法继承的。 5.3 效率 使用CGLib实现动态代理，CGLib底层采用ASM字节码生成框架，使用字节码技术生成代理类，在jdk6之前比使用Java反射效率要高。唯一需要注意的是，CGLib不能对声明为final的方法进行代理，因为CGLib原理是动态生成被代理类的子类。 在jdk6、jdk7、jdk8逐步对JDK动态代理优化之后，在调用次数较少的情况下，JDK代理效率高于CGLIB代理效率，只有当进行大量调用的时候，jdk6和jdk7比CGLIB代理效率低一点，但是到jdk8的时候，jdk代理效率高于CGLIB代理，总之，每一次jdk版本升级，jdk代理效率都得到提升，而CGLIB代理有点跟不上步伐。 总结：当目标对象没有实现接口时，必须采用CGLIB代理，其他情况尽量采用JDK动态代理。","permalink":"http://Charles-xcz.github.io/2020/03/13/设计模式—代理模式/","photos":[]},{"tags":[{"name":"JVM","slug":"JVM","permalink":"http://Charles-xcz.github.io/tags/JVM/"},{"name":"GC","slug":"GC","permalink":"http://Charles-xcz.github.io/tags/GC/"}],"title":"JVM学习(5)——G1垃圾收集器","date":"2020/03/13","text":"引言以前收集器的特点： 年轻代和老年代是各自独立且连续的内存块； 年轻代收集使用单Eden+S0+S1进行复制算法； 老年代收集必须扫描整个老年代区域； 都是以尽可能少而快速地执行GC为设计原则。 CMS垃圾收集器虽然减少了暂停应用程序的运行时间，但是它还存在内存碎片的问题。 于是为了去除内存碎片的问题，同时保留CMS低暂停时间的优点，Java7发布了一个新的垃圾收集器——G1垃圾收集器。在Java9中，G1作为默认垃圾收集器。 1. 概述 G1（Garbage-First），是一款面向服务端垃圾的收集器，应用在多处理器和大容量内存环境中，在实现高吞吐量的同时，尽可能的满足垃圾收集暂停时间的要求。它的设计目标是取代CMS收集器。尽量满足：吞吐量+响应能力。 G1算法将堆划分为若干个区域（Region），它仍然属于分代收集器。 这些Region的新生代部分，垃圾收集依然采用暂停所有应用线程的方式，将存活对象拷贝到老年代或者Survivor空间。 这些Region的老年代部分，G1收集器通过将对象从一个区域复制到另外一个区域，完成了清理工作。 这就意味着，在正常的处理过程中，G1完成了堆的压缩（至少是部分堆的压缩），这样也就不会有CMS内存碎片问题的存在了。 在G1中，还有一种特殊的区域，叫Humongous（巨大的）区域： 如果一个对象占用的空间超过了分区容量50%以上，G1收集器就认为这是一个巨型对象。 这些巨型对象默认直接会被分配在年老代，但是如果它是一个短期存在的巨型对象，就会对垃圾收集器造成负面影响。 为了解决这个问题，G1划分了一个Humongous区，它用来专门存放巨型对象。 如果一个H区装不下一个巨型对象，那么G1会寻找连续的H分区来存储。为了能找到连续的H区，有时候不得不启动Full GC。 2. 主要改变 heap被划分为一个个相等的不连续的内存区域（regions），每个region都有一个分代的角色； eden、survivor、old对每个角色的数量并没有强制的限定，也就是说对每种分代内存的大小，可以动态变化； G1最大的特点就是高效的执行回收，优先去执行那些大量对象可回收的区域（region）。 G1使用了gc停顿可预测的模型，来满足用户设定的gc停顿时间。 根据用户设定的目标时间，G1会自动地选择哪些region要清除，一次清除多少个region； G1从多个region中复制存活的对象，然后集中放入一个region中，同时整理、清除内存（copying收集算法）。 G1 vs CMS G1在压缩空间方面有优势； 对比使用mark-sweep的CMS，G1将内存空间分成若干Region，并使用的copying算法不会造成内存碎片； Eden、Survivor、Old区不在固定，在内存使用效率上来说更灵活； G1可以通过设置预期停顿时间（Pause Time）来控制垃圾收集时间，避免应用雪崩现象； G1在回收内存后会马上同时做合并空闲内存的工作，而CMS默认是在STW（stop the world）的时候做； G1会在Young GC中使用，而CMS只能在Old区使用； 对比Parallel Scavenge（基于copying）、Parallel Old收集器（基于mark-compact-sweep）对整个区域做整理导致gc停顿会比较长，而G1只是特定地整理几个region； G1并非一个实时的收集器，与parallel Scavenge一样，对gc停顿时间的设置并不绝对生效，只是G1有较高的几率保证不超过设定的gc停顿时间。与之前的gc收集器对比，G1会根据用户设定的gc停顿时间，智能评估哪几个region需要被回收可以满足用户的设定。 3. 重要概念1. 分区（Region）G1采取了不同的策略来解决并行、串行和CMS收集器的碎片、暂停时间不可控等问题。 G1将整个堆分成相同大小的分区（Region）： 每个分区都可能是年轻代也可能是老年代，但是在同一时刻只能属于某个代。 年轻代、幸存区、老年代这些概念还存在，成为逻辑上的概念，这样方便复用之前分代框架的逻辑。 在物理上不需要连续，则带来了额外的好处 有的分区内垃圾对象特别多，有的分区内垃圾对象很少，G1会优先回收垃圾对象特别多的分区，这样可以花费较少的时间来回收这些分区的垃圾，这也就是G1名字的由来，即首先收集垃圾最多的分区。 依然是在新生代满了的时候，对整个新生代进行回收 整个新生代中的对象，要么被回收、要么晋升，至于新生代也采取分区机制的原因，则是因为这样跟老年代的策略统一，方便调整代的大小。 G1还是一种带压缩的收集器，在回收老年代的分区时，是将存活的对象从一个分区拷贝到另一个可用分区，这个拷贝的过程就实现了局部的压缩。 2. 收集集合（CSet） 一组可被回收的分区的集合。 Young GC时CSet就是所有年轻代里面的Region。 Mixed GC时CSet是所有年轻代里的Region加上在全局并发标记阶段标记出来的收益高的Region。 位于CSet的Region中的存活数据会在GC过程中被移动到另一个可用分区。 3. 已记忆集合（RSet） 一个谁引用了我的机制，记录引用了当前region的分区内对象的卡片索引。 当要回收该分区时，通过扫描分区的RSet，来确定引用本分区内的对象是否存活，如引用本分区的对象全是垃圾，则当前分区内的对象可能也是垃圾。 RSet的价值在于使得垃圾收集器不需要扫描整个堆找到谁引用了当前分区中的对象，只需要扫描RSet即可。 逻辑上说每个Region都有一个RSet，RSet记录了其他Region中的对象引用本Region中对象的关系，属于points-into结构（谁引用了我的对象）。 而Card Table则是一种points-out（我引用了谁的对象）的结构，每个Card 覆盖一定范围的Heap（一般为512Bytes）。 G1的RSet是在Card Table的基础上实现的：默认情况下，每个card都未被引用。 当一个地址空间被引用时，这个地址空间对应的数组索引的值被标记为’0’，即标记为脏引用，此外RSet也将这个数组下标记录下来，并标记这些引用该地址的指针来自哪些Region的哪些Card。这个RSet其实是一个Hash Table，Key是别的Region的起始地址，Value是一个集合，里面的元素是Card Table的Index。 由于新生代有多个，那么我们需要在新生代之间记录引用吗？ 这是不必要的，原因在于每次GC时，所有新生代都会被扫描，所以只需要记录老年代和新生代以及老年代之间的引用即可。 4. GC模式G1提供了两种GC模式，Young GC和Mixed GC，两种都是需要Stop The World的。 1. Young GCYoung GC：选定所有年轻代里的Region。通过控制年轻代的Region个数，即年轻代内存大小，来控制YoungGC的时间开销。 Young GC主要是对Eden区进行GC，它在Eden空间耗尽时会被触发。 在这种情况下，Eden空间的数据移动到Survivor空间中，如果Survivor空间不够，Eden空间的部分数据会直接晋升到老年代空间。 Survivor区的数据移动到新的Survivor区中，也有部分数据晋升到老年代空间中。在回收之后所有之前属于Eden的区块全部变成空白，即不属于任何一个分区（Eden、Survivor、Old）。 GC完成工作，应用线程继续执行。 2. Mixed GCMixed GC：选定所有年轻代里的Region和根据global concurrent marking统计得出收集收益高的部分老年代Region。在用户指定的开销目标范围内尽可能选择收益高的老年代Region。 分为global concurent marking和拷贝存活对象两步。 global concurent marking：执行过程类似于CMS，但是不同的是，在G1 GC中，它主要是为Mixed GC提供标记服务的，并不是一次GC过程的一个必须环节。执行过程分为四个步骤： 初始标记（initial mark，STW）： 它标记了从GC Root开始直接可达的对象； initial mark是共用了Young GC的暂停，这是因为他们可以复用root scan操作，所以可以说global concurrent marking是伴随Young GC而发生的。 并发标记（Concurrent Marking） 这个阶段从GC Root开始对heap中的对象进行标记，标记线程与应用程序线程并发执行，并且收集各个Region的存活对象信息。 采用的三色标记算法，在下文介绍。 重新标记（Remark，STW）：标记那些在并发标记阶段发生变化的对象，将被回收。 清理（Cleanup） 清除空Region（没有存活对象的），加入free list。 只是回收了没有存活对象的Region，所以它并不需要STW。 注意：Mixed GC不是Full GC 它只能回收部分老年代的Region； 如果Mixed GC实在无法跟上程序分配内存的速度，导致老年代填满无法继续进行Mixed GC，就会使用serial old GC（Full GC）来收集整个GC heap； 所以本质上，G1是不提供Full GC的。 什么时候触发MixedGC? Mixed GC是由一些参数控制，另外也通过参数控制着哪些老年代Region会被选入CSet（收集集合）。 G1HeapWastePercent：在global concurrent marking结束之后，我们可以知道old gen regions中有多少空间要被回收，在每次YGC之后和再次发生Mixed GC之前，会检查垃圾占比是否达到此参数，只有达到了，下次才会发生Mixed GC。 G1MixedGCLiveThresholdPercent：old generation region中的存活对象的占比，只有在此参数之下的Region，才会被选入CSet。 G1MixedGCCountTarget：一次global concurrent marking之后，最多执行Mixed GC的次数。 G1OldCSetRegionThresholdPercent：一次Mixed GC中能被选入CSet的最多old generation region数量。 常用参数表 5. 并发标记 — 三色标记算法三色标记算法：它是描述追踪式回收器的一种有效的方法，利用它可以推演回收器的正确性。 我们将对象分为三种类型： 黑色：根对象，或者该对象与它的子对象都被扫描过（对象被标记了，且它的所有field也被标记完了） 灰色：对象本身被扫描，但还没扫描完该对象中的子对象（它的field还没有被标记或标记完） 白色：未被扫描对象，扫描完成所有对象之后，最终为白色的为不可达对象，即垃圾对象（对象没有被标记到） 步骤： 首先根对象标记为黑色，子对象被置为灰色； 继续由灰色遍历，将已扫描了子对象的对象置为黑色 遍历了所有可达的对象后，所有可达的对象都变成了黑色。不可达的对象即为白色，需要被清理 但是如果在标记过程中，应用程序也在运行，那么对象的指针就有可能改变。这样的话，我们就会遇到一个问题：漏标。 当垃圾收集器扫描到下面图1的情况； 这时候应用程序执行了以下操作：A.c=C; B.c=null;这样，对象的状态图变成图2情形； 这时候垃圾收集器再标记扫描的时候就会变成图3； 很显然，此时C是白色，被认为是垃圾需要清理掉，显然这是不合理的。 这时就需要使用的是SATB（Snapshot-At-The-Beginning）的方式，来解决这种问题。 6. SATBSATB全称snapshot-at-the-beginning，由Taiichi Yuasa为增量式标记清除垃圾收集器开发的一个算法，主要应用于垃圾收集的并发标记阶段， 它有3个步骤： 在开始标记的时候生成一个快照图，标记存活对象。 在并发标记的时候所有被改变的对象入队（在write barrier里把所有旧的引用所指向的对象都变成非白的）。 可能存在浮动垃圾，将在下次被收集。 SATB是维持并发GC的一种手段。G1并发的基础就是SATB。 SATB可以理解成在GC开始之前对堆内存里的对象做一次快照，此时活的对象就认为是活的，从而形成一个对象图。 在GC收集的时候，新生代的对象也认为是活的对象，除此之外其他不可达的对象都认为是垃圾对象。 如何找到在GC过程中分配的对象呢？ 每个region记录着两个top-at-mark-start（TAMS）指针，分别为prevTAMS和nextTAMS。在TAMS以上的对象就是新分配的，因而被视为隐式marked。 通过这种方式我们就找到了在GC过程中新分配的对象，并把这些对象认为是活的对象。 Region包含了5个指针，分别是bottom、previous TAMS、next TAMS、top和end 其中previous TAMS、next TAMS是前后两次发生并发标记时的位置，全称top-at-mark-start， 1、假设并发标记开始，将该Region当前的top指针赋值给next TAMS，在并发标记标记期间，分配的对象都在[next TAMS, top]之间，SATB能够确保这部分的对象都会被标记，默认都是存活的。 2、当并发标记结束时，将next TAMS所在的地址赋值给previous TAMS，SATB给 [bottom, previous TAMS] 之间的对象创建一个快照Bitmap，所有垃圾对象能通过快照被识别出来 那么在GC过程中引用发生变化的问题怎么解决呢？ 对black新引用了一个white对象，然后又从gray对象中删除了对该white对象的引用，这样会造成了该white对象漏标记 对black新引用了一个white对象，然后从gray对象删了一个引用该white对象的white对象，这样也会造成了该white对象漏标记 对black新引用了一个网刚new出来的white对象，没有其他gray对象引用该white对象，这样也会造成了该white对象漏标记 对于三色算法在concurrent的时候可能产生的漏标记问题，SATB在marking阶段中，对于从gray对象移除的目标引用对象标记为gray，对于black引用的新产生的对象标记为black；由于是在开始的时候进行snapshot，因而可能存在Floating Garbage。 漏标与误标 误标没什么关系，顶多造成浮动垃圾，在下次gc还是可以回收的。 但是漏标的后果是致命的，把本应该存活的对象给回收了，从而影响的程序的正确性 漏标的情况只会发生在白色对象中，且满足以下任意一个条件： 并发标记时，应用线程给一个黑色对象的引用类型字段赋值了该白色对象。 并发标记时，应用线程删除所有灰色对象到该白色对象的引用。 对于第一种情况，利用post-write barrier，记录所有新增的引用关系，然后根据这些引用关系为根重新扫描一遍。 对于第二种情况，利用pre-write barrier，将所有即将被删除的引用关系的旧引用记录下来，最后以这些旧引用为根重新扫描一遍。 7. 停顿预测模型G1收集器突出表现出来的一点是通过一个停顿预测模型根据用户配置的停顿时间来选择CSet的大小，从而达到用户期待的应用程序暂停时间。 通过-XX:MaxGCPauseMillis参数来设置。这一点有点类似于ParallelScavenge收集器。 关于停顿时间的设置并不是越短越好。 设置的时间越短意味着每次收集的CSet越小，导致垃圾逐步积累变多，最终不得不退化成SerialOld GC。 停顿时间设置的过长，那么会导致每次都会产生长时间的停顿，影响了程序对外的响应时间。 8. G1调优实践不断调优暂停时间指标 通过-XX:MaxGCPauseMillis=x可以设置启动应用程序暂停的时间； G1在运行的时候会根据这个参数选择CSet来满足响应时间的设置。 一般情况下这个值设置到100ms或者200ms都是可以的（不同情况下会不一样），但如果设置成50ms就不太合理。暂停时间设置的太短，就会导致出现G1跟不上垃圾产生的速度。最终退化成FullGC。 所以对这个参数的调优是一个持续的过程，逐步调整到最佳状态。 不要设置新生代和老年代的大小 G1收集器在运行的时候会调整新生代和老年代的大小。 通过改变代的大小来调整对象晋升的速度以及晋升年龄，从而达到我们为收集器设置的暂停时间目标。 若手动设置了新生代大小相当于放弃了G1为我们做的自动调优。我们需要做的只是设置整个堆内存的大小，剩下的交给G1自己去分配各个代的大小即可。 关注Evacuation Failure Evacuation Failure类似于CMS里面的晋升失败，堆空间的垃圾太多导致无法完成Region之间的拷贝，于是不得不退化成Full GC来做一次全局范围内的垃圾收集。","permalink":"http://Charles-xcz.github.io/2020/03/13/JVM学习(5)——G1垃圾收集器/","photos":[]},{"tags":[{"name":"JVM","slug":"JVM","permalink":"http://Charles-xcz.github.io/tags/JVM/"},{"name":"GC","slug":"GC","permalink":"http://Charles-xcz.github.io/tags/GC/"}],"title":"JVM学习(4)——GC垃圾收集器","date":"2020/03/13","text":"1. 介绍GC垃圾收集器是GC算法的实现。 主要分为四种： Serial：串行垃圾收集器（又分为Serial和Serial Old） 它为单线程环境设计且只使用一个线程进行垃圾回收，会暂停所有用户线程。所以不适合服务器环境。 Parallel：并行垃圾收集器（又分为Parallel Scavenge、ParNew和Parallel Old） 多个垃圾收集线程并行工作，此时用户线程是暂停的，适用于科学计算/大数据处理等弱交互场景 CMS：并发垃圾收集器 用户线程和垃圾收集线程同时执行（不一定是并行，可能交替执行），不需要停顿用户线程。 互联网公司多用它，适用于对响应时间有要求的场景。 G1：G1内容比较多，参见《JVM学习(5)——G1垃圾收集器》。 查看服务器的使用的垃圾回收器：-XX:PrintCommandLineFlags Java中的7种GC垃圾收集器：开启方式如：-XX:+UseParallelGC UseSerialGC、UseSerialOldGC、UseParallelGC、UserParallelOldGC、UseParNewGC、UseConcMarkSweepGC、UseG1GC 2. 详情部分参数： DefNew——Default New Generation Tenured——Old ParNew——Parallel New Generation PSYoungGen——Parallel Scavenge ParOldGen——Parallel Old Generation 1. Serial​ 串行垃圾收集器是最古老，最稳定以及效率最高的收集器，只使用一个线程去回收但其在进行垃圾收集过程中可能会产生较长的停顿（Stop-The-World 状态）。虽然在收集垃圾的过程中需要暂停所有其他的工作线程，但它简单高效，对于限定单个cpu环境来说，没有线程交互的开销可以获得最高的单线程垃圾收集效率。因此，Serial垃圾收集器依然是Java虚拟机运行在Client模式下默认的新生代垃圾收集器。 开启参数：-XX:+UseSerialGC 开启后会使用Serial（Young区）+Serial Old（Old区）的收集器组合。 新生代、老年代都会使用串行垃圾收集器，新生代使用复制算法，老年代使用标记-整理算法。 2. ParNew​ ParNew收集器其实就是Serial收集器新生代的并行多线程版本，最常见的应用场景是配合老年代的CMS GC工作，其余的行为和Serial收集器完全一样，ParNew垃圾收集器在垃圾收集过程中同样也要暂停所有其他的工作线程。它是很多java虚拟机运行在Server模式下新生代的默认垃圾收集器。 开启参数：-XX:+UseParNewGC 启用ParNew收集器，只影响新生代的收集，不影响老年代。 开启上述参数后，会使用：ParNew（Young区用）+Serial Old的收集器组合。新生代使用复制算法，老年代采用标记-整理算法。 但是，ParNew+Tenured这样的搭配，Java8已经不再推荐。deprecated 注：-XX:ParallelGCThreads，修改限制线程数量，默认开启和CPU数量相同的线程的数。 3. Parallel Scavenge​ Parallel Scavenge收集器类似ParNew也是一个新生代垃圾收集器，使用复制算法，也是一个并行的多线程的垃圾收集器，俗称吞吐量优先收集器。 它关注的重点是： 可控制的吞吐量（Thoughput=运行用户代码时间/（运行用户代码时间+垃圾收集时间））。高吞吐量意味着高效利用CPU时间，它多用于后台运算而不需要太多交互的任务。 自适用调节策略也是Parallel Scavenge收集器与ParNew收集器的一个重要区别。 自适用调节策略：虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最适合的停顿时间（-XX:MaxGCPauseMillis）或最大吞吐量 开启参数：-XX:+UseParallelGC或-XX:+UseParallerOldGC（二者可互相激活） 默认情况下Java8的配置。 开启上述参数后，会使用 Parallel Scavenge+UserParallelOldGC的收集器组合。新生代使用复制算法，老年代采用标记-整理算法。 4. Serial Old单线程的标记-整理算法，主要运行在Client默认的Java虚拟机的老年代垃圾收集器。 在Server模式下，主要有两个用途： 在JDK1.5之前版本中与Parallel Scavenge收集器搭配使用。 作为老年代中使用CMS收集器的后备垃圾收集器。 5. ParallelOld​ ParallelOldGC在JDK1.6才开始出现，在1.6之前，新生代使用Parallel Scavenge收集器只能搭配老年代的Serial Old收集器。只能保证新生代的吞吐量优先，无法保证整体的吞吐量。 6. CMS​ 并发标记清除GC（Concurrent Mark Sweep）是一种以获取最短回收停顿时间为目标的收集器。适合应用在互联网或者B/S系统的服务器上，这类应用尤其重视服务器响应速度，希望系统停顿时间最短。 CMS非常适合堆内存大、CPU核数多的服务器应用，也是G1出现之前大型应用的首选收集器。 并发收集低停顿，并发指与用户线程并发执行。 开启参数：-XX:+UseConcMarkSweepGC 开启该参数后会自动将-XX:+UseParNewGC打开。 开启该参数后，使用ParNew（Young区）+CMS（Old区）+Serial Old的组合。Serial Old会作为CMS出错的后备收集器。 四步过程： 初始标记（CMS initial mark）：只是标记以下GC Roots能直接关联的对象，速度很快，仍然需要暂停所有的工作线程。 并发标记（CMS concurrent mark） 进行GC Roots跟踪过程，和用户线程一起工作，不需要暂停工作线程。 主要标记过程，标记全部对象。 重新标记（CMS remark） 为了修正在并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分标记记录，仍然需要暂停所有的工作线程。 由于并发标记时，用户线程依然运行，因此在正式清理前，再做修正。 在CMS中，为了在并发标记阶段结束后，可以快速找到哪些card有引用更新，因此将老年代内存分为很多个Card，再使用Card Table维护每个card是否在并发标记阶段有引用变化，如果变化了，我们就说这个Card是Dirty的，这样可以提高重新标记阶段的速度。 如果引用了发生了变化，则标记1。标记时，采用了bit位的方式标记，大大节省了空间，如byte=3的二进制位0000 0011,从右到左，第1位可以表示dirtyCard，第2位可以表示有引用年轻代，这样在Young gc时，也可以通过Card Table快速找到需要扫描的老年代card，无需扫描整个老年代。（很多博文上说一个Card管理512Bytes的heap）。 并发清除（CMS concurrent sweep） 清除GC Roots不可达对象，和用户线程一起工作，不需要暂停工作线程。基于标记结果，直接清理对象。 CMS以流水线方式拆分了收集周期，将耗时长的操作单元保持与应用线程并发执行。只将那些必需STW才能执行的操作单元单独拎出来，控制这些单元在恰当的时机运行，并能保证仅需短暂的时间就可以完成。这样，在整个收集周期内，只有两次短暂的暂停（初始标记和重新标记），达到了近似并发的目的。 优点： 并发收集、低停顿。 缺点： 并发执行，对CPU资源压力大 由于并发进行，CMS收集线程与应用线程会同时会增加对堆内存的用，也就是说，CMS必须要在老年代堆内存用尽之前完成垃圾回收，否则CMS回收失败时，将触发担保机制，串行老年代收集器将会以STW的方式进行一次GC，从而造成较大停顿时间。 采用的标记清除算法会导致大量碎片。 标记清除算法无法整理空间碎片，老年代空间会随着应用时长被逐步耗尽，最后将不得不通过担保机制对堆内存进行压|缩。CMS也提供了参数-XX:CMSFulIGCsBeForeCompaction（默认0，即每次都进行内存整理）来指定多少次CMS收集之后，进行一次压缩的Full GC。 3. 垃圾收集器的选择 单CPU或小内存，单机程序 -XX:+UseSerialGC 多CPU，需要大吞吐量，如后台计算型应用 -XX:+UseParallelGC或-XX:+UseParallelOldGC 多CPU，追求低停顿时间，需要快速响应，如互联网应用 -XX:+UseConcMarkSweepGC 参数 新生代垃圾收集器 新生代算法 老年代垃圾收集器 老年代算法 -XX:+UseSerialGC SerialGC 复制 SerialOldGC 标整 -XX:+UseParNewGC ParNew 复制 SerialOldGC 标整 -XX:+UseParallelGC/-XX:+UseParallelOldGC Parallel Scavenge 复制 ParallelOld 标整 -XX:+UseConcMarkSweepGC ParNew 复制 CMS+SerialOld组合 标清 -XX:+UseG1GC G1整体上采用标记-整理算法 局部是通过复制算法，不会产生内存碎片","permalink":"http://Charles-xcz.github.io/2020/03/13/JVM学习(4)——GC垃圾收集器/","photos":[]},{"tags":[{"name":"JVM","slug":"JVM","permalink":"http://Charles-xcz.github.io/tags/JVM/"},{"name":"GC","slug":"GC","permalink":"http://Charles-xcz.github.io/tags/GC/"}],"title":"JVM学习(3)——GC Roots与四种引用","date":"2020/03/12","text":"引言什么是垃圾，简单来说就是内存中已经不在被使用的空间就是垃圾。 如何判断一个对象可以被回收？ 引用计数法（JVM中不使用这种算法） 枚举根节点做可达性分析（根搜索路径） 因为引用计数法会导致循环引用问题，所以Java使用了可达性分析的方法来判别垃圾。 1. GC Roots​ 所谓GC Roots就是用来Tracing GC的根集合，是一组必须活跃的引用。 ​ 基本思路就是通过一系列名为 GC Roots 的对象作为起始点，从这个被称为GC Roots的对象开始向下搜索，如果一个对象到GC Roots没有任何引用链相连时，则说明此对象不可用。 ​ 也即给定一个集合的引用作为根出发，通过引用关系遍历对象图，能被遍历到的（可到达的）对象就被判定为存活，没有被遍历到的就自然被判定为死亡。 哪些对象可以作为GC Roots 虚拟机栈（栈帧中的局部变量区，也叫做局部变量表）中引用的对象。 方法区中的类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中Native方法引用的对象。 2. 强引用​ 当内存不足，JVM开始垃圾回收，对于强引用的对象，就算是出现了OOM也不会对该对象进行回收，死都不收。 ​ 强引用是我们最常见的普通对象引用，只要还有强引用指向一个对象，就能表明对象还“活着”，垃圾收集器不会碰这种对象。 ​ 在Java中最常见的就是强引用，把一个对象赋给一个引用变量，这个引用变量就是一个强引用。 ​ 当一个对象被强引用变量引用时，它处于可达状态，它是不可能被垃圾回收机制回收的，即使该对象以后永远都不会被用到JVM也不会回收。因此强引用是造成Java内存泄漏的主要原因之一。 ​ 对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为null，一般认为就是可以被垃圾收集的了（当然具体回收时机还是要看垃圾收集策略）。 3. 软引用 SoftReference softReference = new SoftReference&lt;&gt;(Obj); ​ 软引用是一种相对强引用弱化了一些的引用，需要用java.lang.ref.SoftReference类来实现，可以让对象豁免一些垃圾收集。 ​ 对于只有软引用的对象来说， 当系统内存充足时它不会被回收， 当系统内存不足时它会被回收。 ​ 软引用通常用在对内存敏感的程序中，比如高速缓存就有用到软引用，内存够用的时候就保留，不够用就回收！ /** * VM options: -Xms5m -Xmx5m */ public class SoftReferenceDemo { public static void softRefMemoryEnough() { Object o1=new Object(); SoftReference&lt;Object> softReference = new SoftReference&lt;>(o1); o1 = null; System.gc(); System.out.println(o1); System.out.println(softReference.get()); } public static void softRefMemoryNotEnough() { Object o1=new Object(); SoftReference&lt;Object> softReference = new SoftReference&lt;>(o1); o1 = null; try { byte[] bytes = new byte[30 * 1024 * 1024]; } catch (Throwable e) { e.printStackTrace(); }finally { System.out.println(o1); System.out.println(softReference.get()); } } public static void main(String[] args) { softRefMemoryEnough(); softRefMemoryNotEnough(); } } /** * 输出结果表明：内存足够时，软引用不会被回收，内存不足时会被回收。 * null * java.lang.Object@1b6d3586 * * java.lang.OutOfMemoryError: Java heap space * at jvm.reference.SoftReferenceDemo.softRefMemoryNotEnough(SoftReferenceDemo.java:23) * at jvm.reference.SoftReferenceDemo.main(SoftReferenceDemo.java:34) * null * null */ 4. 弱引用 WeakReference 无论内存是否充足，只要GC都会被回收。 软引用和弱引用的应用场景： 假如有一个应用需要读取大量的本地图片： 如果每次读取图片都从硬盘读取则会严重影响性能， 如果一次性全部加载到内存中又可能造成内存溢出。 此时使用软引用可以解决这个问题。 ​ 设计思路是：用一个HashMap来保存图片的路径和相应图片对象关联的软引用之间的映射关系. ​ 在内存不足时，JVM会自动回收这些缓存图片对象所占用的空间，从而有效地避免了OOM的问题。 ​ Map&lt;String,SoftReference&gt;imageCache =new HashMap&lt;String,SoftReference&gt;(); WeakHashMap运用的弱引用 /** * 输出结果为： * {888=hashMap} * {} */ public class WeakHashMapDemo { public static void main(String[] args) { myWeakHashMap(); } public static void myWeakHashMap() { WeakHashMap&lt;Integer, String> map = new WeakHashMap&lt;>(); Integer key = 999; String value = \"hashMap\"; map.put(key, value); key = null; System.out.println(map); System.gc(); System.out.println(map); } } 5. 虚引用 PhantomReference，又称幽灵引用 ​ 顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。 ​ 如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收，它不能单独使用也不能通过它访问对象，虚引用必须和引用队列（ReferenceQueue）联合使用。（注：其他引用也可以和引用队列联合使用） ​ 虚引用的主要作用是跟踪对象被垃圾回收的状态。仅仅是提供了一种确保对象被finalize以后，做某些事情的机制。 ​ PhantomReference的get方法总是返回null，因此无法访问对应的引用对象。其意义在于说明一个对象已经进入finalization阶段，可以被gc回收，用来实现比finalization机制更灵活的回收操作。 ​ 换句话说，设置虚引用关联的唯一目的，就是在这个对象被收集器回收的时候收到一个系统通知或者后续添加进一步的处理。Java 技术允许使用finalize()方法在垃圾收集器将对象从内存中清除出去之前做必要的清理工作。 /** * null * null * ============== * null * java.lang.ref.PhantomReference@1b6d3586 */ public class ReferenceQueueDemo { public static void main(String[] args) { Object o1 = new Object(); ReferenceQueue&lt;Object> referenceQueue = new ReferenceQueue&lt;>(); PhantomReference&lt;Object> reference = new PhantomReference&lt;>(o1, referenceQueue); System.out.println(reference.get()); System.out.println(referenceQueue.poll()); System.out.println(\"==============\"); o1 = null; System.gc(); System.out.println(reference.get()); System.out.println(referenceQueue.poll()); } } ​ 创建引用的时候可以指定关联的队列，当GC释放对象内存的时候，会将引用加入到引用队列如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动了这相当于是一种通知机制。 ​ 当关联的引用队列中有数据的时候，意味着引用指向的堆内存中的对象被回收。通过这种方式，JVM允许我们在对象被销毁后，做一些我们自己想做的事情。 6. 总结","permalink":"http://Charles-xcz.github.io/2020/03/12/JVM学习(3)——GC Roots与四种引用/","photos":[]},{"tags":[{"name":"多线程","slug":"多线程","permalink":"http://Charles-xcz.github.io/tags/多线程/"},{"name":"线程池","slug":"线程池","permalink":"http://Charles-xcz.github.io/tags/线程池/"}],"title":"多线程——线程池","date":"2020/03/11","text":"1. 创建线程的3种方法 继承Thread类 实现Runnable接口 实现Callable接口 public class CallableDemo { public static void main(String[] args) throws ExecutionException, InterruptedException { int result; FutureTask&lt;Integer> futureTask = new FutureTask&lt;>(new MyThread3()); new Thread(futureTask, \"A\").start(); new Thread(futureTask, \"B\").start(); System.out.println(\"main线程执行其他操作\"); TimeUnit.SECONDS.sleep(2); while (!futureTask.isDone()) { } //要求获得Callable线程的返回结果,如果没有计算完成会导致阻塞,直到计算完成 //所以建议futureTask.get()放在后面,不会阻塞main线程去执行其他工作 Integer integer = futureTask.get(); result = integer + 10; System.out.println(\"返回结果为-->\" + result); } } class MyThread1 extends Thread { } class MyThread2 implements Runnable { @Override public void run() { } } class MyThread3 implements Callable&lt;Integer> { @Override public Integer call() throws Exception { System.out.println(\"***come in callable***\"); TimeUnit.SECONDS.sleep(3); return 1024; } } 2. 使用线程池优势​ 线程池做的工作主要是控制运行的线程的数量，处理过程中将任务放入队列，然后在线程创建后启动这些任务，如果线程数量超过了最大数量，超出数量的线程排队等候，等其它线程执行完毕，再从队列中取出任务来执行。 主要特点为：线程复用，控制最大并发数，管理线程。 优点 降低资源消耗。通过重复利用己创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 3. 线程池的实现​ Java中的线程池是通过Executor框架实现的，该框架中用到了Executor，Executors，ExecutorService，ThreadPoolExecutor这几个类。 Executors.newFixedThreadPool(int) 创建一个定长线程池，可控制线程最大并发数，超出的线程会在阻塞队列中等待。 newFixedThreadPool创建的线程池corePoolSize和maximumPoolSize值是相等的，它使用的LinkedBlockingQueue。 public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable>()); } Executors.newSingleThreadExecutor() 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序执行。 newSingleThreadExecutor将corePoolSize和maximumPoolSize都设置为1，它使用的LinkedBlockingQueue。 public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable>())); } Executors.newCachedThreadPool() 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。 newCached ThreadPool将corePoolSize设置为0，将maximumPoolSize设置为Integer.MAX_VALUE，使用的是SynchronousQueue，也就是说来了任务就创建线程运行，当线程空闲超过60秒，就销毁线程。 public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable>()); } Executors.newScheduledThreadPool() Executors.newWorkStealingPool(int) 注意：线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 说明：Executors返回的线程池对象的弊端如下： FixedThreadPool和SingleThreadPool：允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，从而导致OOM CachedThreadPool和ScheduledThreadPool：允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致OOM。 4. 线程池七大参数 corePoolSize：线程池中的常驻核心线程数 在创建了线程池后，当有请求任务来之后，就会安排池中的线程去执行请求任务，近似理解为今日当值线程。 当线程池中的线程数目达到coreloolSize后，就会把到达的任务放到缓存队列当中。 maximumPoolSize：线程池能够容纳同时执行的最大线程数，此值必须大于等于1。 keepAliveTime：多余的空闲线程的存活时间。 当前线程池数量超过corePoolSize时，当空闲时间达到keepAliveTime值时，多余空闲线程会被销毁直到只剩下corePoolSize个线程为止。 unit：keepAliveTime的单位。 workQueue：任务队列，被提交但尚未被执行的任务。 threadFactory：表示生成线程池中工作线程的线程工厂，用于创建线程一般用默认的即可。 handler：拒绝策略，表示当队列满了并且工作线程大于等于线程池的最大线程数（maximumPoolSize）时如何来处理。 5. 线程池底层原理 处理流程： 6. 拒绝策略 AbortPolicy（默认）：直接抛出RejectedExecutionException异常阻止系统正常运行。 CallerRunsPolicy：“调用者运行“一种调节机制，该策略既不会抛弃任务，也不会抛出异常，而是将某些任务回退到调用者，从而降低新的任务流量。 DiscardoldestPolicy：抛弃队列中等待最久的任务，然后把当前任务加入队列中尝试再次提交当前任务。 DiscardPolicy：直接丢弃任务，不予任何处理也不抛出异常。如果允许任务丢失，这是最好的一种方案。 7. 手写线程池public class MyThreadPoolDemo { public static void main(String[] args) { ExecutorService threadPool = new ThreadPoolExecutor( 2, 5, 1L, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;>(3), Executors.defaultThreadFactory(), new ThreadPoolExecutor.CallerRunsPolicy()); try { for (int i = 0; i &lt; 15; i++) { threadPool.execute(() -> { System.out.println(Thread.currentThread().getName() + \" 来办理业务\"); }); } } catch (Exception e) { e.printStackTrace(); } finally { threadPool.shutdown(); } } } 8. 线程数量考虑CPU密集型： CPU密集的意思是该任务需要大量的运算，而没有阻塞，CPU一直全速运行。 CPU密集任务只有在真正的多核CPU上才可能得到加速（通过多线程），而在单核CPU上，无论你开几个模拟的多线程该任务都不可能得到加速，因为CPU总的运算能力就那些。 CPU密集型任务配置尽可能少的线程数量： 一般公式：CPU核数+1个线程的线程池 IO密集型： 由于IO密集型任务线程并不是一直在执行任务，则应配置尽可能多的线程。 IO密集型，即该任务需要大量的IO，即大量的阻塞。 在单线程上运行IO密集型的任务会导致浪费大量的CPU运算能力浪费在等待。 所以在IO密集型任务中使用多线程可以大大的加速程序运行，即使在单核CPU上，这种加速主要就是利用了被浪费掉的阻塞时间。 IO密集型时，大部分线程都阻塞，故需要多配置线程数。 两种说法： 如CPU核数*2 CPU核数/1-阻塞系数 阻塞系数在0.8~0.9之间。比如8核CPU：8/1-0.9=80个线程数","permalink":"http://Charles-xcz.github.io/2020/03/11/多线程——线程池/","photos":[]},{"tags":[{"name":"多线程","slug":"多线程","permalink":"http://Charles-xcz.github.io/tags/多线程/"},{"name":"BlockingQueue","slug":"BlockingQueue","permalink":"http://Charles-xcz.github.io/tags/BlockingQueue/"}],"title":"线程阻塞和阻塞队列","date":"2020/03/11","text":"1. 阻塞线程的几个工具类1.1 CountDownLatch CountDownLatch：让一些线程阻塞直到另一些线程完成一系列操作后才被唤醒。 ​ CountDownLatch主要有两个方法，当一个或多个线程调用await方法时，调用线程会被阻塞。 ​ 其它线程调用countDown方法会将计数器减1（调用countDown方法的线程不会阻塞），当计数器的值变为零时，因调用await方法被阻塞的线程会被唤醒，继续执行。 public class CountDownLatchDemo { public static void main(String[] args) throws InterruptedException { //计数器的值设为6 CountDownLatch countDownLatch = new CountDownLatch(6); for (int i = 0; i &lt; 6; i++) { new Thread(() -> { System.out.println(Thread.currentThread().getName() + \" 离开教室\"); countDownLatch.countDown(); }, String.valueOf(i)).start(); } //线程阻塞，直到计数器减到0，线程被唤醒 countDownLatch.await(); System.out.println(Thread.currentThread().getName()+\"===管理员锁门===\"); } } 1.2 CyclicBarrier CyclicBarrier的字面意思是可循环（Cyclic）使用的屏障（Barrier）。 ​ 它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续执行，线程进入屏障通过CyclicBarrier的await）方法。 public class CyclicBarrierDemo { public static void main(String[] args) { //当有七个线程到达同步点，执行方法 CyclicBarrier cyclicBarrier = new CyclicBarrier(7, () -> { System.out.println(\"****召唤神龙****\"); }); for (int i = 1; i &lt;= 7; i++) { final int finalI = i; new Thread(() -> { System.out.println(Thread.currentThread().getName() + \" 收集到第\" + finalI + \"颗龙珠\"); try { //被阻塞，同步点 cyclicBarrier.await(); } catch (InterruptedException | BrokenBarrierException e) { e.printStackTrace(); } }, String.valueOf(i)).start(); } } } 1.3 Semaphore 信号量主要用于两个目的，一个是用于多元共享资源的互斥使用，另一个用于并发线程数的控制。 public class SemaphoreDemo { public static void main(String[] args) { //设定三个共享资源，只有抢到资源的能够执行 //即最多个线程可以同时执行，其他线程需要等待资源被释放才能抢占资源。 Semaphore semaphore = new Semaphore(3); for (int i = 1; i &lt;= 7; i++) { final int finalI = i; new Thread(() -> { try { semaphore.acquire(); System.out.println(Thread.currentThread().getName() + \"-->抢到资源\"); TimeUnit.SECONDS.sleep(3); System.out.println(Thread.currentThread().getName() + \"-->3s后释放了资源\"); } catch (InterruptedException e) { e.printStackTrace(); }finally { semaphore.release(); } }, String.valueOf(i)).start(); } } } 2. BlockingQueue​ 当阻塞队列是空时，从队列中获取元素的操作将会被阻塞。 ​ 当阻塞队列是满时，往队列里添加元素的操作将会被阻塞。 ​ 在多线程领域：所谓阻塞，在某些情况下会挂起线程（即阻塞），一旦条件满足，被挂起的线程又会自动被唤醒。 为什么需要BlockingQueue ​ 好处是我们不需要关心什么时候需要阻塞线程，什么时候需要唤醒线程，因为这一切BlockingQueue都给你一手包办了。 ​ 在concurrent包发布以前，在多线程环境下，我们每个程序员都必须去自己控制这些细节，尤其还要兼顾效率和线程安全，而这会给我们的程序带来不小的复杂度。 2.1 核心方法四组操作 方法类型 抛出异常 特殊值 阻塞 超时 插入 add(e) offer(e) put(e) offer(e,time,unit) 移除 remove() poll() take() poll(time,unit) 检查 element() peek() 不可用 不可用 抛出异常 当阻塞队列满时，再往队列里add插入元素会抛 IllegalStateException:Queue full 当阻塞队列空时，再往队列里remove移除元素会抛 NoSuchElementException 特殊值 插入方法，成功ture 失败false 移除方法，成功返回出队列的元素，队列里面没有就返回null 一直阻塞 当阻塞队列满时，生产者线程继续往队列里put元素，队列会一直阻塞生产线程直到put数据or响应中断退出。 当阻塞队列空时，消费者线程试图从队列里take元素，队列会一直阻塞消费者线程直到队列可用。 超时 当阻塞队列满时，队列会阻塞生产者线程一定时间，超时则返回false 2.2 实现类 ArrayBlockingQueue：由数组结构组成的有界阻塞队列。 LinkedBlockingQueue：由链结构组成的有界（但大小默认值为Integer.MAX_VALUE）阻塞队列。注意默认值 PriorityBlockingQueue：支持优先级排序的无界阻塞队列。 DelayQueue：使用优先级队列实现的延迟无界阻塞队列。 SynchronousQueue：不存储元素的阻塞队列，也即单个元素的队列。 LinkedTransferQueue：由链表结构组成的无界阻塞队列。 LinkedBlockingDeque：由链表结构组成的双向阻塞队列 SynchronousQueue没有容量 ​ 与其他BlockingQueue不同，SynchronousQueue是一个不存储元素的BlockingQueue。 ​ 每一个put操作必须要等待一个take操作，否则不能继续添加元素，反之亦然。 2.3 使用场景1. 生产者与消费者 传统方式实现： public class ProducerConsumer { public static void main(String[] args) { ShareData shareData = new ShareData(); //生产 new Thread(() -> { for (int i = 0; i &lt; 5; i++) { try { shareData.increment(); } catch (InterruptedException e) { e.printStackTrace(); } } }, \"AA\").start(); //消费 new Thread(() -> { for (int i = 0; i &lt; 5; i++) { try { shareData.decrement(); } catch (InterruptedException e) { e.printStackTrace(); } } }, \"BB\").start(); } } class ShareData { private int number = 0; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); public void increment() throws InterruptedException { lock.lock(); try { //1.判断 用while,防止虚假唤醒 while (number != 0) { //等待,不能生产 condition.await(); } //2.操作 number++; System.out.println(Thread.currentThread().getName() + \"\\t\" + number); //3.通知唤醒 condition.signalAll(); } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } } public void decrement() throws InterruptedException { lock.lock(); try { //1.判断 用while,防止虚假唤醒 while (number == 0) { //等待,不能生产 condition.await(); } //2.操作 number--; System.out.println(Thread.currentThread().getName() + \"\\t\" + number); //3.通知唤醒 condition.signalAll(); } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } } } 阻塞队列方式实现 public class ProConsumerBlockingQueue { public static void main(String[] args) throws InterruptedException { Resource resource = new Resource(new ArrayBlockingQueue&lt;>(10)); new Thread(() -> { System.out.println(Thread.currentThread().getName() + \"\\t生产线程启动\"); try { resource.myProd(); } catch (InterruptedException e) { e.printStackTrace(); } }, \"AA\").start(); new Thread(() -> { System.out.println(Thread.currentThread().getName() + \"\\t消费线程启动\"); try { resource.myConsumer(); } catch (InterruptedException e) { e.printStackTrace(); } }, \"BB\").start(); TimeUnit.SECONDS.sleep(5); System.out.println(\"5秒钟,终止\"); resource.stop(); } } class Resource { private volatile Boolean flag = true; private AtomicInteger atomicInteger = new AtomicInteger(); BlockingQueue&lt;Object> blockingQueue; public Resource(BlockingQueue&lt;Object> blockingQueue) { this.blockingQueue = blockingQueue; System.out.println(blockingQueue.getClass().getName()); } public void myProd() throws InterruptedException { String data; boolean retVal; while (flag) { data = atomicInteger.incrementAndGet() + \"\"; retVal = blockingQueue.offer(data, 2L, TimeUnit.SECONDS); if (retVal) { System.out.println(Thread.currentThread().getName() + \"\\t 插入数据:\" + data); } else { System.out.println(Thread.currentThread().getName() + \"\\t 插入数据失败:\"); } TimeUnit.SECONDS.sleep(1); } System.out.println(Thread.currentThread().getName() + \"\\tflag变为false,生产停止\"); } public void myConsumer() throws InterruptedException { String result; while (flag) { result = (String) blockingQueue.poll(2L, TimeUnit.SECONDS); if (null == result || \"\".equalsIgnoreCase(result)) { flag = false; System.out.println(Thread.currentThread().getName() + \" 消费退出\"); return; } System.out.println(Thread.currentThread().getName() + \"\\t 取出数据:\" + result); } } public void stop() { this.flag = false; } } 2. 线程池底层实现​ 线程池的底层实现也用到了阻塞队列。 ​ 线程池详情参见《多线程——线程池》","permalink":"http://Charles-xcz.github.io/2020/03/11/多线程——线程阻塞和阻塞队列/","photos":[]},{"tags":[{"name":"多线程","slug":"多线程","permalink":"http://Charles-xcz.github.io/tags/多线程/"},{"name":"锁","slug":"锁","permalink":"http://Charles-xcz.github.io/tags/锁/"}],"title":"synchronized和Lock的一些对比","date":"2020/03/11","text":"1. 公平锁与非公平锁 公平锁：是指多个线程按照申请锁的顺序来获取锁，FIFO。 非公平锁：是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁，在高并发的情况下，有可能会造成优先级反转或者饥饿现象 Lock lock = new ReentrantLock(); //默认为非公平锁 等同new ReentrantLock(false); Lock lock = new ReentrantLock(true); //公平锁 2. 可重入锁​ 指的是同一线程外层函数获得锁之后，内层递归函数仍然能获取该锁的代码，同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁。 ​ 即：线程可以进入任何一个他已经拥有锁的同步代码块。 ​ 可重入锁最大的作用是避免死锁 ​ ReentrantLock和Synchronized是典型的可重入锁 3. 自旋锁​ 是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去试获取锁。 ​ 这样的好处是减少线程上下文切换的消耗。 ​ 缺点是循环会消耗CPU。 例如前面博客《并发编程之—— CAS》介绍到的CAS的实现就是自旋锁。 public final int getAndAddInt(Object var1, long var2, int var4) { int var5; do { var5 = this.getIntVolatile(var1, var2); } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; } 4. 独占锁/共享锁 独占锁：该锁一次只能被一个进程持有。对ReentrantLock和Synchronized而言都是独占锁。 共享锁：指该锁可被多个线程持有。 对ReentrantReadWriteLock而言，其读锁是共享锁，其写锁是独占锁。 读锁的共享锁可保证并发读是非常高效的，读写，写读，写写的过程是互斥的。 ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); //写锁，是互斥的 lock.writeLock().lock(); .......... lock.writeLock().unlock(); //读锁是共享的 lock.readLock().lock(); .......... lock.readLock().unlock(); 5. synchronized和Lock区别 原始构成不同 synchronized是关键字，属于JVM层面 monitorenter，monitorexit 底层是通过monitor对象来完成，其实wait/notify 等方法也依赖monitor对象只有在同步块或方法中才能调wait/notify等方法 Lock是具体类(java.util.concurrent.locks.Lock)，是api层面 使用方法 synchronized不需要手动释放锁，当synchronized代码执行完后，系统会自动让线程释放对锁的占用 ReentrantLock则需要用户手动释放锁，若没有手动释放可能导致死锁现象 等待是否可中断 synchronized不可中断，除非是抛出异常或正常运行结束 ReentrantLock可中断 设置超时方法 tryLock(long timeout,TimeUnit unit) lockUnterruptibly放代码块中，调用interrupt()方法可中断 加锁是否公平 synchronized 只能是非公平锁 ReentrantLock 默认非公平，但构造方法传入参数true可设置为公平锁 锁绑定多个条件condition synchronized没有 ReentrantLock用来实现分组唤醒需要唤醒的线程们，可以精确唤醒，而不是像synchronized要么随机唤醒一个线程要么唤醒全部线程。 Lock精确唤醒示例： class ShareData1 { /** * A:1,B:2,C:3 */ private int number = 1; private Lock lock = new ReentrantLock(); private Condition c1 = lock.newCondition(); private Condition c2 = lock.newCondition(); private Condition c3 = lock.newCondition(); public void print1() { lock.lock(); try { //1.判断 while (number != 1) { c1.await(); } //2.操作 for (int i = 0; i &lt; 5; i++) { System.out.println(Thread.currentThread().getName() + \"--> \" + i); } number = 2; //3.通知 c2.signal(); } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } } public void print2() { lock.lock(); try { //1.判断 while (number != 2) { c2.await(); } //2.操作 for (int i = 0; i &lt; 5; i++) { System.out.println(Thread.currentThread().getName() + \"--> \" + i); } number = 3; //3.通知 c3.signal(); } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } } public void print3() { lock.lock(); try { //1.判断 while (number != 3) { c3.await(); } //2.操作 for (int i = 0; i &lt; 5; i++) { System.out.println(Thread.currentThread().getName() + \"--> \" + i); } number = 1; //3.通知 c1.signal(); } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } } }","permalink":"http://Charles-xcz.github.io/2020/03/11/synchronized和Lock/","photos":[]},{"tags":[{"name":"多线程","slug":"多线程","permalink":"http://Charles-xcz.github.io/tags/多线程/"},{"name":"CAS","slug":"CAS","permalink":"http://Charles-xcz.github.io/tags/CAS/"}],"title":"并发编程之—— CAS","date":"2020/03/11","text":"引言 CAS：Compare-And-Swap 比较并交换，它是一条CPU并发原语 它的功能是判断内存某个位置的值是否为预期值，如果是则更改为新的值，这个过程是原子的。 1. CAS的底层原理原子整型的原子自增就是通过CAS的原理实现的。 AtomicInteger atomicInteger=new AtomicInteger(5); atomicInteger.getAndIncrement; 下面通过AtomicInteger类的源码例子来了解CAS是什么： public class AtomicInteger extends Number implements java.io.Serializable { private static final long serialVersionUID = 6214790243416807050L; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static { try { valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(\"value\")); } catch (Exception ex) { throw new Error(ex); } } private volatile int value; ....... /** * Atomically increments by one the current value. * * @return the previous value */ public final int getAndIncrement() { return unsafe.getAndAddInt(this, valueOffset, 1); } 可以看到AtomicInteger类中引入了一个Unsafe类，CAS是通过Unsafe类实现的。 先了解一下Unsafe类 Unsafe是CAS的核心类，由于Java方法无法直接访问底层系统，需要通过本地（native）方法来访问，Unsafe相当于一个后门，基于该类可以直接操作特定内存的数据。Unsafe类存在于sun.misc包中，其内部方法操作可以像C的指针一样直接操作内存，因为Java中CAS操作的执行依赖于Unsafe类的方法。 ​ 注意：Unsafe类中的所有方法都是native修饰的，也就是Unsafe类中的方法都直接调用操作系统层资源执行相应任务。 变量valueOffset，表示该变量值在内存中的偏移地址，因为Unsafe类就是根据内存偏移地址获取数据的。 变量value用volatile修饰，保证了多线程之间的内存可见性。 //Unsafe类中的getAndAddInt方法 public final int getAndAddInt(Object var1, long var2, int var4) { int var5; do { var5 = this.getIntVolatile(var1, var2); } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; } ​ CAS并发原语在JAVA语言中就是sun.misc.Unsafe类中的各个方法实现的。 ​ 调用UnSafe类中的CAS方法，JVM会帮我们实现出CAS汇编指令。这是一种完全依赖于硬件的功能，通过它实现了原子操作。 ​ 再次强调，由于CAS是一种系统原语，原语属于操作系统用语范畴，是由若干条指令组成的，用于完成某个功能的一个过程，并且原语的执行必须是连续的，在执行过程中不允许被中断，也就是说CAS是一条CPU的原子指令，不会造成所谓的数据不一致问题。 ​ 假设线程A和线程B两个线程同时执行getAndAddlnt操作实现过程（分别跑在不同CPU上）： Atomiclnteger里面的value原始值为3，即主内存中Atomiclnteger的value为3，根据JMM模型，线程A和线程B各自持有一份值为3的value的副本分别到各自的工作内存。 线程A通过getIntVolatile(var1,var2)拿到value值3，这时线程A被挂起。 线程B也通过getIntVolatile(var1,var2)方法获取到value值3，此时刚好线程B没有被挂起并执行compareAndSwaplnt方法比较内存值也为3，成功修改内存值为4，线程B完成收工，一切OK。 这时线程A恢复，执行compareAndSwaplnt方法比较，发现自己手里的值数字3和主内存的值数字4不一致，说明该值己经被其它线程抢先一步修改过了，那A线程本次修改失败，只能重新读取重新来一遍了。 线程A重新获取value值，因为变量value被volatile修饰，所以其它线程对它的修改，线程A总是能够看到，线程A继续执行compareAndSwaplnt进行比较替换，直到成功。 即：比较当前工作内存的值和主内存中的值，如果相同则执行规定操作，否则继续比较直到主内存和工作内存中的值一致为止。 2. CAS缺点 由于通过do while循环实现，可能导致循环时间长，cpu开销大。 只能保证一个共享变量的原子操作。 当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就要使用锁来保证原子性。 引出来ABA问题 3. ABA问题​ CAS算法实现一个重要前提需要取出内存中某时刻的数据并在当下时刻比较并替换，那么在这个时间差类会导致数据的变化。 ​ 比如说一个线程1从内存位置V中取出A，这时候另一个线程2也从内存中取出A，并且线程2进行了一些操作将值变成了B，然后线程2又将V位置的数据变成A，这时候线程1进行CAS操作发现内存中仍然是A，然后线程1操作成功。 ​ 尽管这个过程线程1的CAS操作成功，但内存V位置的值中间产生了变化，有时这种问题会造成影响，这就叫做ABA问题。 解决ABA问题 ​ 新增一种机制，版本号（类似于时间戳） 原子引用：AtomicInteger，只是对基本类型进行原子操作，要想对对象进行原子操作，可使用原子引用类型。 AtomicReference&lt;T> //不带版本号 AtomicReference&lt;Integer> 等同于 AtomicInteger AtomicStampedReference&lt;T> //带版本号的原子引用，可以解决ABA问题","permalink":"http://Charles-xcz.github.io/2020/03/11/并发编程之—— CAS/","photos":[]},{"tags":[{"name":"JVM","slug":"JVM","permalink":"http://Charles-xcz.github.io/tags/JVM/"}],"title":"JVM学习(2)——JVM的内存以及GC算法","date":"2020/03/09","text":"一. 方法区 Method Area属于供各线程共享的运行时内存区域。 它存储了每一个类的结构信息，例如运行时常量池（Runtime Constant Poo1）、字段和方法数据、构造函数和普通方法的字节码内容。 方法区所说的是一种规范，在不同虚拟机里头实现是不一样的，最典型的就是： 永久代（PermGen Space） JDK7 中的实现 元空间（Meta Space） JDK8 中的实现 实例变量存在堆内存中，和方法区无关。 二. Stack栈也叫栈内存，主管Java程序的运行，是在线程创建时创建，它的生命期是跟随线程的生命期，线程结束栈内存也就释放，对于栈来说不存在垃圾回收问题，只要线程一结束该栈就0ver，生命周期和线程一致，是线程私有的。 8种基本类型的变量+对象的引用变量+实例方法都是在函数的栈内存中分配。 栈帧中主要保存3类数据：（每个方法入栈就是一个栈帧） 本地变量（Local Variables）：输入参数和输出参数以及方法内的变量； 栈操作（Operand Stack）：记录出栈、入栈的操作； 栈帧数据（Frame Data）：包括类文件、方法等等。 栈运行原理： 栈中的数据都是以栈帧（Stack Frame）的格式存在，栈帧是一个内存区块，是一个数据集，是一个有关方法（Method）和运行期数据的数据集，当一个方法A被调用时就产生了一个栈帧F1，并被压入到栈中，A方法又调用了B方法，于是产生栈帧F2也被压入栈，B方法又调用了C方法，于是产生栈帧F3也被压入栈，执行完毕后，先弹出F3栈帧，再弹出F2栈帧，再弹出F1栈帧…… 遵循“先进后出”/“后进先出”原则。 每个方法执行的同时都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接、方法出口等信息，每一个方法从调用直至执行完毕的过程，就对应着一个栈帧在虚拟机中入栈到出栈的过程。栈的大小和具体JVM的实现有关，通常在256K~756K之间，与等于1Mb左右。 //Exception in thread \"main\" java.lang.StackOverflowError 栈溢出错误 public Class Test{ public static void m1(){ m1(); } public static void main(String[]args){ m1(); } } Java堆+栈+方法区的交互关系 HotSpot是使用指针的方式来访问对象。 Java堆中会存放r访问类元数据的地址，reference存储的就是直接对象的地址。 三. 堆Heap堆的划分 逻辑上 新生代 (Young/New Generation Space) 伊甸园区(Eden Space) 幸存者0区(Survivor 0 Space) 幸存者1区(Survivor 1 Space) 老年代(Tenure/Old Generation Space) 永久代(Permanent Space)(Java7之前)/元空间(Meta Space)(Java8) 物理上 新生代 老年代 1. 新生代​ 新生区是类的诞生、成长、消亡的区域，一个类在这里产生，应用，最后被垃圾回收器收集，结束生命。 ​ 新生区又分为两部分：伊甸区（Eden space）和幸存者区（Survivor pace），所有的类都是在伊甸区被new出来的。 ​ 幸存者区有两个：0区（Survivor 0 space）和1区（Survivor 1 space）。 ​ 当伊甸园的空间用完时，程序又需要创建对象，JVM的垃圾回收器将对伊甸园区进行垃圾回收（Minor GC），将伊甸园区中的不再被其他对象所引用的对象进行销毁。然后将伊甸园中的剩余对象移动到幸存0区。若幸存0区也满了，再对该区进行垃圾回收，然后移动到1区。那如果1区也满了呢？再移动到养老区。 ​ 若养老区也满了，那么这个时候将产生MajorGC(Full GC)，进行养老区的内存清理。若养老区执行了Fu11 GC之后发现依然无法进行对象的保存，就会产生OOM异常“OutOfMemoryError”。 如果出现java.lang.OutOfMemoryError:Java heap space异常，说明Java虚拟机的堆内存不够。原因有二：（1）Java虚拟机的堆内存设置不够，可以通过参数-Xms、-Xmx来调整。（2）代码中创建了大量大对象，并且长时间不能被垃圾收集器收集（存在被引用）。 2. Minor GC的过程（复制-&gt;清空-&gt;互换） 首先，当Eden区满的时候会触发第一次GC，把还活着的对象拷贝到SurvivorFrom区。经历一次复制，年龄+1。 在触发GC的时候，对象只会存在于Eden区和名为“From”的Survivor区，Survivor区“To”是必定是空的。 紧接着进行GC，Eden区中所有存活的对象都会被复制到“To”，而在“From”区中，仍存活的对象会根据他们的年龄值来决定去向。年龄达到一定值（年龄阈值，默认为15。可以通过-XX:MaxTenuringThreshold来设置）的对象会被移动到年老代中，没有达到阈值的对象会被复制到“To”区域。 经过这次GC后，Eden区和From区已经被清空。这个时候，“From”和“To”会交换他们的角色，也就是新的“To”就是上次GC前的“From”，新的“From”就是上次GC前的“To”。不管怎样，都会保证名为To的Survivor区域是空的。 Minor GC会一直重复这样的过程，直到“To”区被填满，“To”区被填满之后，会将所有对象移动到年老代中。 3. 永久代​ 实际而言，方法区（Method Area）和堆一样，是各个线程共享的内存区域。 ​ 它用于存储虚拟机加载的：类信息+普通常量+静态常量+编译器编译后的代码等等。 ​ 虽然JVM规范将方法区描述为堆的一个逻辑部分，但它却还有一个别名叫做Non-Heap（非堆），目的就是要和堆分开。 ​ 对于HotSpot虚拟机，很多开发者习惯将方法区称之为“永久代（Parmanent Gen）”，但严格本质上说两者不同，或者说使用永久代来实现方法区而已，永久代是方法区的一个实现，Jdk1.7的版本中，已经将原本放在永久代的字符串常量池移走。 ​ 永久存储区是一个常驻内存区域，用于存放JDK自身所携带的Class，Interface的元数据，也就是说它存储的是运行环境必须的类信息，被装载进此区域的数据是不会被垃圾回收器回收掉的，关闭JVM才会释放此区域所占用的内存。 4. 堆参数调整 在Java8中，永久代已经被移除，被一个称为元空间的区域所取代。元空间的本质和永久代类似。 元空间与永久代之间最大的区别在于： 永久代使用的JVM的堆内存，但是java8以后的元空间并不在虚拟机中而是使用本机物理内存。 因此，默认情况下，元空间的大小仅受本地内存限制。类的元数据放入native memory，字符串池和类的静态变量放入java堆中，这样可以加载多少类的元数据就不再由MaxPermSize控制，而由系统的实际可用空间来控制。 JVM默认情况下分配的初始堆内存为机器物理内存的1/64，最大为1/4 可以通过代码查看： /** * 查看虚拟机内存情况 * @author charles * @date 2020/3/1 16:51 */ public class MyTest1 { public static void main(String[] args) { System.out.println(\"cpu核数:\"+Runtime.getRuntime().availableProcessors()); System.out.println(\"初始分配内存Xms: \"+Runtime.getRuntime().totalMemory()/(double)1024/1024+\" MB\"); System.out.println(\"最大分配内存Xmx: \"+Runtime.getRuntime().maxMemory()/(double)1024/1024+\" MB\"); } } 修改VM参数后： VM options: -Xms1024m -Xmx1024m -XX:+PrintGCDetails 写个程序造成OOM异常，观察下GC日志 OOM异常：Exception in thread “main” java.lang.OutOfMemoryError: Java heap space 先将将分配空间调小 -Xms10m -Xmx10m -XX:+PrintGCDetails public class MyTest1 { public static void main(String[] args) { //new 一个超出限制的对象，或者写个循环 new大量的对象 byte[] bytes = new byte[20 * 1024 * 10244]; } } GC日志： [GC (Allocation Failure) [PSYoungGen: 1564K->488K(2560K)] 1564K->684K(9728K), 0.0007243 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (Allocation Failure) [PSYoungGen: 504K->0K(2560K)] [ParOldGen: 268K->593K(7168K)] 772K->593K(9728K), [Metaspace: 3173K->3173K(1056768K)], 0.0054369 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] GC日志解读： Full GC结构类似。 五. GC算法 GC: Garbage Collection 1. GC算法概述GC 分代收集算法 次数上频繁收集Young区 次数上较少收集Old区 基本不动元空间 ​ JVM在进行GC时，并非每次都对上面三个内存区域一起回收的，大部分时候回收的都是指新生代。 ​ 因此GC按照回收的区域又分了两种类型，一种是普通GC（minorGC），一种是全局GC（major GC or Full GC） Minor GC和Full GC的区别 ​ 普通GC（minorGC）：只针对新生代区域的GC，指发生在新生代的垃圾收集动作，因为大多数Java对象存活率都不高，所以Minor GC非常频繁，一般回收速度也比较快。 ​ 全局GC（major GCor Full GC）：指发生在老年代的垃圾收集动作。出现了Major GC，经常会伴随至少一次的Minor GC（但并不是绝对的）。Major GC的速度一般要比Minor GC慢上10倍以上 2. 四大算法1. 引用计数法 注意：JVM的实现基本不采用该算法。 应用：（微软的COM/ActionScrip3/Python.… ） 给对象添加一个引用计数器，每当一个地方引用它时，计数器加1，每当引用失效时，计数器减少1。当计数器的数值为0时，也就是对象无法被引用时，表明对象不可再使用，这种方法实现简单，效率较高，大部分情况下不失为一个有效的方法。但是主流的Java虚拟机如HotSpot并没有选取引用计数法来回收内存，主要的原因难以解决对象之间的相互循环引用的问题。优点：实现简单，效率较高。 缺点： 每次对象赋值时均要维护引用计数器，且计数器本身也有一定的消耗。 较难处理循环引用。 2. 复制算法（Copying） 年轻代中使用的Minor GC，就是采用的复制算法。 ​ 因为年轻代的对象基本都是朝生夕死的（90%以上），所以在年轻代的垃圾回收算法使用的是复制算法。 ​ 复制算法的基本思想就是将内存分为两块，每次只用其中一块，当这一块内存用完，就将还活着的对象复制到另外一块上面。复制算法不会产生内存碎片。 优点： 没有标记和清除的过程，效率高。 没有内存碎片，可快速分配内存 缺点： 浪费空间：要从From区复制到To区，等于浪费一半的空间。 如果对象的存活率很高，我们可以极端一点，假设是100%存活，那么我们需要将所有对象都复制一遍，并将所有引用地址重置一遍。复制这一工作所花费的时间，在对象存活率达到一定程度时，将会变的不可忽视。所以从以上描述不难看出，复制算法要想使用，最起码对象的存活率要非常低才行，而且最重要的是，我们必须要克服50%内存的浪费。 ​ 因为Eden区对象一般存活率较低：一般的，使用两块10%的内存作为空闲和活动区间，而另外80%的内存，则是用来给新建对象分配内存的。一旦发生GC，将10%的from活动区间与另外80%中存活的eden对象转移到10%的to空闲区间，接下来，将之前90%的内存全部释放，以此类推。 ​ 具体的Minor GC的过程，前面已经论述过了，不再赘述。 3. 标记清除（Mark-Sweep） 老年代一般是由标记清除或者是标记清除与标记整理的混合实现。 算法分成标记和清除两个阶段，先标记出要回收的对象，然后统一回收这些对象。例如 ​ 先标记处要回收的对象(蓝色)，然后清除这些对象。 优点：不需要额外空间。 缺点： 耗时严重：两次扫描，效率比较低（递归与全堆对象遍历），而且在进行GC的时候，需要停止应用程序，这会导致用户体验非常差劲 产生内存碎片：这种方式清理出来的空闲内存是不连续的，这点不难理解，我们的死亡对象都是随即的出现在内存的各个角落的，现在把它们清除之后，内存的布局自然会乱七八糟。而为了应付这一点，JVM就不得不维持一个内存的空闲列表，这又是一种开销。而且在分配数组对象的时候，寻找连续的内存空间会不太好找。 4. 标记压缩（Mark-Compact） 实际上就是标记清除和标记整理(压缩)的结合。 ​ 先标记，然后再次扫描，将存活对象向一端移动。在整理压缩阶段，不对标记的对象进行回收，而是将所有存活对象移动到一端后，直接清除边界以外的内存。 优点： 不需要额外空间 没有内存碎片 缺点：需要移动对象，效率低 标记-清除-压缩 ​ 属于一种优化，就是多次GC（采用Mark-Sweep），后进行一次Compact。 5. 总结 效率方面：复制算法&gt;标记清除算法&gt;标记整理算法（此处的效率只是简单的对比时间复杂度，实际情况不一定如此）。 内存整齐度：复制算法=标记整理算法&gt;标记清除算法。 内存利用率：标记整理算法=标记清除算法&gt;复制算法。 ​ 可以看出，效率上来说，复制算法最优，但是却浪费了太多内存，而为了尽量兼顾上面所提到的三个指标，标记/整理算法相对来说更平滑一些，但效率上依然不尽如人意，它比复制算法多了一个标记的阶段，又比标记/清除多了一个整理内存的过程。 JVM中对GC算法的具体实现体现于不同的GC垃圾收集器。 可参见参见《JVM学习(1)——GC垃圾收集器》、《JVM学习(5)——G1垃圾收集器》","permalink":"http://Charles-xcz.github.io/2020/03/09/JVM学习(2)——JVM内存以及GC算法/","photos":[]},{"tags":[{"name":"JVM","slug":"JVM","permalink":"http://Charles-xcz.github.io/tags/JVM/"}],"title":"JVM学习(1)——类加载、连接与初始化","date":"2020/02/29","text":"在Java代码中，类型的加载、连接与初始化过程都是在程序运行期间完成的。这提供了更大的灵活性，增加了更多的可能性 1. Java虚拟机与程序的生命周期 如下几种情况下，Java虚拟机将结束生命周期 执行了System.exit()方法 程序正常执行结束 程序在执行过程中遇到了异常或错误而异常终止 由于操作系统出现错误而导致Java虚拟机进程终止 2. 加载​ 查找并加载类的二进制数据，就是将二进制形式的Java类型读入Java虚拟机中。 ​ 类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内。然后在内存中创建一个java.lang.Class对象（规范并未说明Class对象位于哪里，HotSpot虚拟机将其放在了方法区中）用来封装类在方法区内的数据结构。 加载.class文件的方式 从本地系统中直接加载 通过网络下载.class文件 从zip，jar等归档文件中加载.class文件 从专有数据库中提取.class文件 将Java源文件动态编译为.class文件 3. 连接​ 类被加载后，就进入连接阶段。分为验证，准备，解析三个阶段 ​ 连接就是将已经读到内存中的类的二进制数据合并到虚拟机的运行环境中去。 ​ 验证：确保被加载类的正确性 ​ 类验证的内容 类文件的结构检查 语义检查 字节码验证 二进制兼容性的验证 ​ 准备：Java虚拟机为类的静态变量分配内存，并将其初始化为默认值 ​ 解析：把类中的符号引用（间接）转换为直接引用 4. 初始化​ 为类的静态变量赋予正确的初始值 ​ 静态变量的声明语句，以及静态代码块都被看做类的初始化语句。 ​ Java虚拟机会按照初始化语句在类文件中的先后顺序依次执行它们。 ​ 类初始化步骤 假如这个类还没有被加载和连接，那就先进行加载和连接 假如类存在直接父类，并且这个父类还没有被初始化，那就先初始化直接父类 假如类中存在初始化语句，那就依次执行这些初始化语句 ​ 类初始化的时机 ​ Java对类的使用方式可分为两种 主动使用 被动使用 ​ 所有的Java虚拟机实现必须要在每个类或接口被Java程序”首次主动使用“时才初始化它们 ​ 主动使用（七种，重要） 创建类的实例（new一个实例） 访问某个类或接口的静态变量，或者对该静态变量赋值 调用类的静态方法 反射（如Class.forName(“com.test.Test”)） 初始化该类的子类 Java虚拟机启动时被标明为启动类的类（包含main（）方法的类） JDK1.7开始提供的动态语言支持 ​ 除了上述七种情况，其他情况都认为是对类的被动使用，因此都不会导致类的初始化 ​ 当Java虚拟机初始化一个类时，要求它的所有父类都已经被初始化，但这条规则不适用于接口。 在初始化一个类时，并不会先初始化它所实现的接口 在初始化一个接口时，并不会先初始化它的父接口 ​ 因此，一个父接口并不会因为它的子接口或者实现类的初始化而初始化。只有当程序首次使用特定接口的静态变量时，才会导致该接口的初始化。 ​ 只有当程序访问的静态变量或静态方法确实在当前类或当前接口中定义时，才可以认为是对类或接口的主动使 5. 类的实例化 为新的对象分配内存 为实例变量赋默认值 为实例变量赋正确的初始值 Java编译器为它编译的每一个类都至少生成一个实例初始化方法，在Java的class文件中，这个实例初始化方法被称为“”。针对源代码中每一个类的构造方法，Java编译器都产生一个方法。 Some Cases/** * 类的初始化 * 虚拟机参数 -XX:+&lt;option> 表示开启 &lt;option> 选项 * -XX:-&lt;option> 表示关闭 &lt;option> 选项 * -XX:&lt;option>=&lt;value> 表示给 &lt;option> 选项赋值 * -XX:+TraceClassLoading 用于追踪类的加载信息并打印出来 * -XX:+TraceClassUnLoading 用于追踪类的卸载信息并打印出来 * * @author charles * @date 2020/2/19 10:40 */ public class MyTest1 { public static void main(String[] args) { /* 对于静态字段来说,只有直接定义了该字段的类才会被初始化 str是在MyParent1中被定义,所以 MyChild1.str是对类 MyParent1 的主动使用, 所以类 MyParent1 会被初始化 */ System.out.println(MyChild1.str); /* str2 是在 MyChild1 中被定义,所以类 MyChild1 会被初始化 初始化一个类的子类时,父类也会被初始化(主动使用) */ System.out.println(MyChild1.str2); } } class MyParent1 { public static String str = \"hello world\"; static { System.out.println(\"MyParent1 static block\"); } } class MyChild1 extends MyParent1 { public static String str2 = \"welcome\"; static { System.out.println(\"MyChild1 static block\"); } } /** * 定义常量的类的初始化: * 常量在编译阶段会存入到调用这个常量的方法的类的常量池中, * 本质上调用类并没有直接引用到定义常量的类,因此并不会触发定义常量类的初始化 * 反编译 javap -c com.charles.jvm.classloader.MyTest2 * 助记符: * ldc:表示将int,float或是String类型的常量值从常量池中推送至栈顶 * bipush:表示将单字节(-128~127)的常量值从常量池中推送至栈顶 * sipush:表示将短整型(-32768~32767)的常量值从常量池中推送至栈顶 * iconst_i:i属于(-1~5)表示将int型的数字i从常量池中推送至栈顶 * * @author charles * @date 2020/2/19 11:21 */ public class MyTest2 { public static void main(String[] args) { /* 这里常量 MyParent2.STR 存放到了类 MyTest2 的常量池中, 之后 MyTest2 与 MyParent2 就没有任何关联了 甚至,我们可以将 MyParent2 的class文件删除 */ System.out.println(MyParent2.STR); } } class MyParent2 { public static final String STR = \"hello world\"; static { System.out.println(\"MyParent2 static block!\"); } } //反编译结果如下 D:\\Develop\\Java\\JavaProject\\JVMStudy\\build\\classes\\java\\main>javap -c com.charles.jvm.classloader.MyTest2 Compiled from \"MyTest2.java\" public class com.charles.jvm.classloader.MyTest2 { public com.charles.jvm.classloader.MyTest2(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"\":()V 4: return public static void main(java.lang.String[]); Code: 0: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #4 // String hello world 5: invokevirtual #5 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return } /** * 当一个常量的值并非编译期间可以确定的,那么其值就不会被放到调用类的常量池中 * 这时在程序运行时,会导致主动使用这个常量所在类,显然会导致这个类被初始化 * * @author charles * @date 2020/2/20 10:24 */ public class MyTest3 { public static void main(String[] args) { System.out.println(MyParent3.STRING); } } class MyParent3 { public static final String STRING = UUID.randomUUID().toString(); static { System.out.println(\"MyParent3 static block\"); } } /** * 创建类的实例,主动使用 * 对于数组实例来说,其类型是由JVM在运行期间动态生成的, * 表示为[Lcom.charles.jvm.classloader.MyParent4这种形式 * 动态生成的类型其父类就是Object * 对于数组来说,JavaDoc经常将构成数组的元素为Component,实际上就是将数组降低一个维度后的类型 * 助记符: * anewarray:表示创建一个引用类型的数组,并将其引用值压入栈顶 * newarray:表示创建一个指定的原始类型的数组,并将其引用值压入栈顶 * * @author charles * @date 2020/2/20 10:33 */ public class MyTest4 { public static void main(String[] args) { /* 首次主动使用才会初始化 */ MyParent4 p1 = new MyParent4(); MyParent4 p2 = new MyParent4(); /* 类的数组的实例,不是对类的主动使用 */ MyParent4[] parent4s = new MyParent4[2]; } } class MyParent4 { static { System.out.println(\"MyParent4 static block\"); } } /** * 当一个接口在初始化时,并不都要求其父接口完成初始化 * 只有当真正使用到父接口的时候(如引用到接中的常量时),才会初始化 * * @author charles * @date 2020/2/20 11:00 */ public class MyTest5 { public static void main(String[] args) { System.out.println(MyChild5.B); } } interface MyParent5 { /** * 接口中的属性,默认为public static final */ int A = 5; } interface MyChild5 extends MyParent5 { int B = new Random().nextInt(); } /** * @author charles * @date 2020/2/20 11:31 */ public class MyTest6 { public static void main(String[] args) { /* 调用了类Singleton中的静态方法,为主动使用,类Singleton被初始化 */ Singleton singleton = Singleton.getInstance(); System.out.println(\"counter1:\" + Singleton.counter1); System.out.println(\"counter2:\" + Singleton.counter2); } } class Singleton { /** * 初始化counter1为1 */ public static int counter1 = 1; /** * 按顺序进行初始化,构造函数执行后,counter1=4,counter2=3 */ private static Singleton singleton = new Singleton(); /** * 然后counter2又被赋值为0 */ public static int counter2 = 8; private Singleton() { /* counter1在前面已经被初始化为1,所以counter1=1+3 */ counter1 += 3; /* 准备阶段的意义 因为准备阶段,整型的默认值为0 所以counter2=0+3 */ counter2 += 3; } public static Singleton getInstance() { return singleton; } }","permalink":"http://Charles-xcz.github.io/2020/02/29/JVM学习(1)——类加载、连接与初始化/","photos":[]},{"tags":[{"name":"多线程","slug":"多线程","permalink":"http://Charles-xcz.github.io/tags/多线程/"},{"name":"volatile","slug":"volatile","permalink":"http://Charles-xcz.github.io/tags/volatile/"}],"title":"并发编程之——volatile","date":"2020/01/29","text":"1. volatile特征 volatile是Java虚拟机提供的轻量级同步机制 1. 保证可见性 某一线程修改了一个变量值并写回主内存后，会马上通知其它使用该变量的线程进行修改 2. 不保证原子性3. 禁止指令重排volatile实现禁止指令重排优化，从而避免多线程环境下程序出现乱序执行的现象。 先了解一个概念，内存屏障（Memory Barrier）又称内存栅栏，是一个CPU指令，它的作用有两个： 保证特定操作的执行顺序 保证某些变量的内存可见性（利用该特性实现volatile的内存可见性） ​ 由于编译器和处理器都能执行指令重排优化。如果在指令间插入一条Memory Barrier则会告诉编译器和CPU，不管什么指令都不能和这条Memory Barrier指令重排序，也就是说通过插入内存屏障禁止在内存屏障前后的指令执行重排序优化。 ​ 内存屏障另外一个作用是强制刷出各种CPU的缓存数据，因此任何CPU上的线程都能读取到这些数据的最新版本。（保证可见性） ​ 对volatile变量进行写操作时，会在写操作后加入一条store屏障指令，将工作内存中的共享变量值刷新回主内存中。 ​ 对volatile变量进行读操作时，会在读操作后加入一条load屏障指令，从主内存中读取共享变量。 想要了解volatile特性的具体含义，我们先来了解一下JMM。 2. JMM​ JMM（Java内存模型 Java Memory Model，简称JMM）本身是一种抽象的概念并不真实存在，它描述的是一组规则或规范，通过这组规范定义了程序中各个变量（包括实例字段，静态字段和构成数组对象的元素）的访问方式。 ​ JMM关于同步的规定： 线程解锁前，必须把共享变量的值刷新回主内存 线程加锁前，必须读取主内存的最新值到自己的工作内存 加锁解锁是同一把锁 ​ 由于JVM运行程序的实体是线程，而每个线程创建时JVM都会为其创建一个工作内存（有些地方称为栈空间），工作内存是每个线程的私有数据区域。 ​ 而Java内存模型中规定所有变量都存储在主内存，主内存是共享内存区域，所有线程都可以访问，但线程对变量的操作（读取赋值等）必须在工作内存中进行。 ​ 线程操作变量时，首先要将变量从主内存拷贝的自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量，各个线程中的工作内存中存储着主内存中的变量副本拷贝，因此不同的线程间无法访问对方的工作内存。 ​ 因此，线程间的通信（传值）必须通过主内存来完成，其简要访问过程如下图： JMM的三大特性 可见性 通过前面对JMM的介绍，我们知道 各个线程对主内存中共享变量的操作都是各个线程拷贝到自己的工作内存进行操作后再写回到主内存中的。 这就可能存在一个线程A修改了共享变量x的值但还未写回主内存时，另外一个线程B又对主内存中同一个共享变量X进行操作，但此时A线程工作内存中共享变量x对线程B来说并不可见，这种工作内存与主内存同步延迟现象就叫作可见性问题 。 原子性 不可分割性，完整性，也即某个线程正在做着某个具体的业务时，中间不可以被加塞或者被分割。需要整体完整，要么同时成功要么同时失败。 volatile不能保证原子性 如何解决原子性问题？ ​ 加synchronized锁 ​ 使用juc下的原子类，例如AtomicInteger原子整型 有序性 计算机在执行程序时，为了提高性能，编译器和处理器的常常会对指令做重排，一般分以下3种 ​ 指令重排，在单线程环境里，要能确保程序最终执行结果和代码顺序执行的结果是一致的。 ​ 处理器在进行重排序时必须要考虑指令之间的数据依赖性 ​ 但是在多线程环境中，线程交替执行，由于编译器优化重排的存在，两个线程中使用的变量能否保证一致性是无法确定的，结果无法预测。 3. 程序示例seek() 方法， number不加volatile修饰时，会在while(myData.number == 0)处死循环 加volatile修饰，程序正常执行，证明了volatile的可见性：当某一线程修改了一个变量值并写回主内存后，会马上通知其它使用该变量的线程进行修改。 atomic() 方法， 加了volatile的情况下，number的输出结果依然小于20000，这就是不能保证原子性 atomicInteger结果为2000，AtomicInteger保证原子性 class MyData { //int number = 0; volatile int number = 0; public void addTo60() { this.number = 60; } public void addPlusPlus() { this.number++; } AtomicInteger atomicInteger = new AtomicInteger(); public void addAtomic() { atomicInteger.getAndIncrement(); } } public class VolatileDemo01 { /** *验证可见性方法 */ public void seek() { MyData myData = new MyData(); new Thread(() -> { System.out.println(Thread.currentThread().getName() + \":come in\"); //加休息1s,为了确保main线程进入循环时number为0 try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } myData.addTo60(); System.out.println(Thread.currentThread().getName() + \":update number to \" + myData.number); }, \"AAA\").start(); while (myData.number == 0) { } System.out.println(Thread.currentThread().getName() + \"is over\"); } /** *验证原子性方法 */ public void atomic() { MyData myData=new MyData(); for (int i = 0; i &lt; 20; i++) { new Thread(() ->{ for (int j = 0; j &lt; 1000; j++) { myData.addPlusPlus(); myData.addAtomic(); } },String.valueOf(i)).start(); } //需要等待上面20个线性计算完成后,再用main线程取得最终结果,看看是多少 //因为默认有两个线程,main线程和后台gc线程 while (Thread.activeCount() > 2) { Thread.yield(); } System.out.println(Thread.currentThread().getName()+\"finally number value:\"+myData.number); System.out.println(Thread.currentThread().getName()+\"finally atomicInteger value:\"+myData.atomicInteger); } } 3. 禁止指令重排作用场景​ 单例模式DCL DCL（Double Check Lock）机制不一定100%线程安全，原因是指令重排序的存在，加入volatile可以禁止指令重排序 ​ 原因在于某一个线程执行到第一次检测，读取到的instance不为null时，instance的引用对象可能没有完成初始化。 ​ instance=new SingletonDemo()；可以分为以下3步完成（伪代码） memory = allocate(); //1.分配对象内存空间 instance(memory); //2.初始化对象 instance = memory; //3.设置instance指向刚分配的内存地址，此时instance！=null ​ 由于步骤2和步骤3不存在数据依赖关系，而且无论重排前还是重排后程序的执行结果在单线程中并没有改变，因此这种重排优化是允许的。 memory=allocate(); //1.分配对象内存空间 instance=memory(); //3.设置instance指向刚分配的内存地址，此时instance!=null，但是对象还没有初始化完成！ instance(memory); //2.初始化对象 ​ 但是指令重排只会保证串行语义的执行的一致性（单线程），但并不会关心多线程间的语义一致性。 ​ 所以当一条线程访问instance不为null时，由于instance实例未必已初始化完成，也就造成了线程安全问题。 关于AtomicInteger类如何保证原子性，参看CAS的原理。","permalink":"http://Charles-xcz.github.io/2020/01/29/并发编程之——volatile/","photos":[]},{"tags":[{"name":"红黑树","slug":"红黑树","permalink":"http://Charles-xcz.github.io/tags/红黑树/"},{"name":"数据结构","slug":"数据结构","permalink":"http://Charles-xcz.github.io/tags/数据结构/"}],"title":"什么是红黑树？","date":"2019/12/10","text":"1. 定义红黑树是满足下列条件的二叉查找树： 每个节点都带有红色或黑色。节点的颜色由以下规则确定： 根节点是黑色的。 所有叶节点都是黑色的。 在沿着从根出发的任何路径上都不允许出现两个连续的红色节点，即：“红色”结点的两个子结点都是“黑色”的。 从任一节点到其每个子孙叶子节点的所有简单路径都包含相同数目的黑色节点（简称黑色高度） 节点X的黑色高度：从节点X到其子孙叶子节点的简单路径中的黑色链的数量。 红黑树的黑色高度：根节点的黑色高度（称为：根节点的阶）红黑树的两种不同定义： 《算法导论》：叶子节点是指，扩充外部叶结点。即叶子节点为空的“黑色”节点 - 可以认为是2-3-4树的二叉树实现 《程序员实用算法》：数据只存储在叶子节点中，内部节点只用于引用； 示例: 《算法导论》中的红黑树,，黑色高度为2。 《程序员实用算法》中的红黑树，黑色高度为2。加粗为黑色结点本文基于《算法导论》的定义介绍。 2. 红黑树 与 2-3-4树红黑树，可等价转化为2-3-4树。 为了更好的理解红黑树，先看一下2-3-4树 2.1 2-3-4树介绍2-3-4树： 2-3-4树： 是二叉查找树的扩展 树中每个节点中有1个或2个或3个关键字，节点内部是有序的。 2-节点：有1个关键字，2个孩子 3-节点：有2个关键字，3个孩子 4-节点：有3个关键字，4个孩子 具有很好的平衡性：所有叶子节点的深度相同。 2-3-4树的查找插入B结点插入结点H 注意：在插入结点过程中，按照自顶向下的方式进行访问，当发现4-节点时，进行分裂。 即：插入结点时在遍历查找插入位置的路线上，凡是遇到4-结点，就对其进行分裂 现在，自顶向下构造一棵2-3-4树 2.2 二叉树来实现2-3-4树2-3-4树中有三类节点： 2-节点，3-节点和4-节点 对于3-节点和4-节点，利用红色链来绑定“内部”节点 红色链所指向的节点为红色节点（红色链下方的结点） 2-节点不变 3-节点变为用红色链连接的两个二叉树节点，指向外部孩子节点的指针为3个，数量不变。 4-节点转化为三个用红色链连接起来的二叉树节点，指向外部孩子节点的指针为4个，数量不变。 这样，2-3-4树就转化成了二叉树。但是，可以看到，2-3-4树对应的二叉树并不唯一，哪种才是等价的红黑树呢？ 2-3-4树的2-节点和4-节点变成成二叉树节点都是唯一的情况，3-节点呢？我们人为的规定，转换成左分支的情况，（左孩子节点小于父节点，二叉查找树的性质）并且在插入新节点的过程中，产生右分支的时候我们需要把它左旋成为左分支情况。这样，2-3-4树就对应成了唯一的二叉树，即红黑树。（红色链连接代表着2-3-4树节点内部的连接，红色链下方的节点表示红色节点） 那么，现在还剩下一个问题，2-3-4树插入节点过程中的4-节点分裂，对应着二叉树怎样的变化呢？ 2-3-4树中，双亲为2-节点时，4-节点的分裂： 2-3-4树4-节点分裂对应着二叉树的颜色向上翻转，当翻转后出现，右分支情况的3-节点时，旋转成左分支情况2-3-4树中，双亲为3-节点时，4-节点的分裂：在对应二叉树中，同样可以用颜色翻转和旋转等价实现。 当反转后，出现两个红色节点连续，显然不满足红黑树的定义，要进行旋转，旋转规则类似与AVL树失衡的旋转处理。 下面的两个旋转情况，和AVL树LL失衡，LR失衡旋转情况相同 3.总结：红黑树，本质上是2-3-4树两类基本操作： 颜色翻转 实质上为4-节点分裂 当某个结点的两个孩子结点都为红色时 将两个红色孩子结点和其黑色双亲结点的颜色翻转旋转 避免出现连续的两条红色链；避免出现单个的红色右链。 出现右的红色链时：对于右的红色链，进行左旋处理 有连续两个红色链时： 依据两个连续的红色链的形状，进行相应的旋转处理（类似AVL树的失衡旋转规则） 看道小试题， 从空树出发，根据待插入的关键字序列 {03,02,01,04,05,06,07,10,09,08}.构建红黑树。 仔细体会一下红黑树的构建过程。 可以画出对应2-3-4树的插入构建过程和红黑树对比加深理解。（节点依次插入，树未发生翻转变化时省略了重复画图）注意：将红色链指向(下方)的节点定义为红色节点，不要迷惑于红色节点的变化","permalink":"http://Charles-xcz.github.io/2019/12/10/聊聊红黑树/","photos":[]},{"tags":[{"name":"网络","slug":"网络","permalink":"http://Charles-xcz.github.io/tags/网络/"}],"title":"距离向量路由选择","date":"2019/11/29","text":"​ 距离向量路由选择是通过对Bellman-Ford算法进行适当修改，找到任意两结点之间的最短路径。 ​ 先介绍一下Bellman-Ford算法： 1 Bellman-Ford算法​ 这个算法基于这样一个事实，如果结点 i 的所有邻站都知道到结点的最短距离，那么求结点 i 和结点 j 之间的最短距离就可以用结点 i 到每个邻站之间的距离分别加上该邻站到结点j的最短距离，然后再从得数中选择最小的一个。 用以下步骤为每个结点创建一个最短距离表 : 1) 结点和它自己之间的最短距离和代价被初始化为0。 2) 一个结点和任何其他结点之间的最短距离被设置为无穷大。一个结点和其他任何结点之间的代价应当给定(如果两个节点之间没有直接连接，可设置为无穷大)。 3) 然后循环执行 算法Dij = min{(ci1+D1j),(ci2+D2j),……..(ciN+DNj)} 2 距离向量路由选择算法1) 在距离向量路由选择中，代价通常就是跳数（即在到达终点之前通过了多少个网络）。因此任意两个邻站之间的代价被设置为1。 2) 每当路由器从它的邻站那里接收到一些信息时，它就要异步地更新自己的路由表。换言之，每个路由器只执行了整个Bellman-Ford算法中的一部分。这个处理过程是分布式的。 3) 在路由器更新了自己的路由表之后，应当将结果发送给它的所有邻站，以便这些邻站也能更新它们的路由表。 4) 每个路由器至少应当保存每条路由的三个信息：目的网络、代价和下一跳。我们称完整的路由表为Table，表中的第i行为Tablei第i行的三个列分别为Tablei.dest，Tablei.cost和Tablei.next。 5) 我们把来自邻站的一条路由信息称为一个R（记录），它只包含了两个信息：R.dest和R.cost。在收到的记录中不包含下一跳信息，因为下一跳就是发送方的源地址。 3 计数到无穷大​ 距离向量路由的缺点是：好消息传得快，坏消息传得慢。要想让路由选择协议能够正常工作，如果一条链路中断了（代价变为无穷大），那么其他所有路由器都应当立刻获知这一情况，但是在距离向量路由选择中，这是要花费一些时间的。这个问题就称为计数到无穷大（count to infinity）。需要经过多次更新才能使所有的路由器都把这条中断链路的代价记录为无穷大。 二结点循环问题: 为了解决这种不稳定性的几种方法： 1) 定义无穷大：距离向量协议一般把16定义为无穷大，即16跳为不可达，但是这也意味着距离向量不能用于大系统。在各个方向上，网络的大小都不能超过15跳。 2) 分割范围：如果结点B根据其路由表认为到达X的最佳路由要经过A，那么它就不需要再把到X的路由通告给A了，因为这个信息就是从A来的（A已经知道了）。从结点A得到信息，修改后再发回给A，这就是产生混乱的根源。所以，结点B在发送路由表给A之前要删除路由表中下一跳为A的路由信息。在这种情况下，结点A保留到X的距离为无穷大。在此之后，当结点A将其路由表发送给B时，结点B也就更正了它的路由表。系统在第一次更新后就变稳定了，因为结点A和B都知道了X是不可达的。 3) 分割范围和毒性逆转：使用分割范围策略有一个缺点。通常，距离向量协议使用一个计时器，若长时间没有关于某个路由的消息，就要从路由表中删除这个路由。在前面描述的场景中，当结点B在它给A的通告中删除了到X的路由时，结点A并不能猜出这是由于分割范围策略(因为信息的来源是A)，还是因为B最近一直都没有收到有关X的任何消息。分割范围策略可以与毒性逆转（poison reverse）策略组合起来使用。结点B可以仍然通知关于X的数值，但如果信息源是A，就把距离换成为无穷大(16)作为一种警告：“不要使用这个数值，我所知道的关于这条路由的信息来自于你。” 三结点不稳定性​ 分割范围和毒性逆转可以用于避免二结点的不稳定性，但如果是三个结点之间，稳定性仍然无法保证。","permalink":"http://Charles-xcz.github.io/2019/11/29/路径向量路由选择/","photos":[]},{"tags":[{"name":"算法","slug":"算法","permalink":"http://Charles-xcz.github.io/tags/算法/"}],"title":"模式匹配—>KMP算法","date":"2019/11/19","text":"引言​ 场景：在字符串：“fffffab cfe defe” 中查找字符串 “ff”。 ​ 被查找的字符串称之为：主串或目标串T ; ​ 想要查找的字符串”ff”称之为：字串或模式串P。 ​ 朴素的模式匹配在匹配过程中需要进行回溯，因而会发生多次重复比较，匹配效率低。故而，需要对字符串查找算法进行优化。 ​ 字符串查找算法中，最著名的算法之一：KMP算 法（Knuth-Morris-Pratt) ​ 它是精确字符串匹配算法（区别于模糊匹配）。 ​ – 目标字符串中无需进行回溯。（比朴素的模式匹配算法快）​ – 模式字符串的移动方向：从目标字符串的第一个字符 开始，朝目标字符串的尾部方向移动搜索匹配子串。 KMP算法1 KMP​ 注意：为了方便，KMP算法中，数组下标一般从1开始。 ​ KMP算法的设计初衷： 希望能在匹配过程中，目标串T中的字符匹配是一直向右前进的，而不会出现向左的回溯。 下面看两个例子 例1：当模式串中无重复时 因为模式串中无重复，因为T[1]=P[1]，T[2]=P[2]，显然T[2]!=P[1]。即第二轮比较多余 同理，2，3，4，5轮的匹配都是多余的。 例2：模式串P中有重复 从图上可以看出2，3，4，5轮，目标串匹配字符i的回溯都是多余的。我们可以直接从1跳到6。 why？？为什么可以跳？怎么跳？ 注意观察模式串字符的规律：这里我们要利用模式串P自身的重复。 下面继续放一些示例： 关注： 匹配失败，是否发生在P的第一个字符处？ ​ P中是否有重复模式？ 分析总结： ​ 前两种情况容易得出： ​ 若当前轮匹配在与P[1]比较就失败，那么 下一轮应该是比较T[i+1]和P[1] ​ 若P中在当前轮成功匹配的子串的后缀与子串的前缀无重复模式，那么下一轮应该是比较T[i]和P[1] ​ 第三种情况： ​ 若P中在当前轮成功匹配的子串的后缀与子串的前缀有重复模式，那么下一轮应该是比较T[i]和P[next[j]] ​ next[j]:在模式串P的下标 j 处失配后，下一轮比较的模式串P的下标，用next数组记录模式串P每个位置失配后下一轮应该比较的位置。 那么next[j] = ？ 在上图 Case1 中，P中无重复模式，下轮比较T[i]和P[1]，下轮比较的模式串下标为1，即next[j]=1; ​ Case2中，P[1]就失配，下轮比较T[i+1]和P[1]，我们用next[j]=0来表示这种情况，代表着在模式串P开头处即失配，目标串下标i向后移动一位。我们把下标为0来代表这种情况，这也是为什么KMP算法下标从1开始计算的原因。 ​ Case3和Case4: 在P[j]处失配，设存在k|1&lt;k&lt;j 使得”P[1]…..P[k-1]“=”P[j-k+1]….P[j-1]” 即模式串P的前k-1位子串与从P[j]处往前k-1位子串相同，即P中在当前轮成功匹配的子串的后缀与子串的前缀有重复模式，则下轮比较从k开始，next[j]=k。 所以： 2 KMP算法思想总结 将模式串P自身的重复规律保存到next数组中 匹配过程：若某轮匹配失败，则利用next数组分 别计算下一轮匹配时目标串和模式串的开始位置若是T[i]≠P[j]导致当前轮的匹配失败，则按照下列规则 开始下一轮匹配： 若next[j] ≠ 0，则将T[i..]与P[next[j]..]匹配； 若next[j]==0，则将T[(i+1)..]与P[1..]匹配。","permalink":"http://Charles-xcz.github.io/2019/11/19/模式匹配——KMP/","photos":[]}]}